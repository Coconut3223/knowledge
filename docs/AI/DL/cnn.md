# CNN

!!! danger "To maintain spatial struture."

!!! p "summary"
    ==Conv==
    - Accept a volume of size $W_1\times H_1\times D_1$
    - Requires 4 hyperparameters
      - Number of filters $K$
      - Filter' size $F$
      - Stride $S$
      - Zero padding $P$
    - Number of weights $(F\times F\times D_1)\times K + K\text{(shared bias)}$
    - Produce a volume of size $(\frac{W_1-F+2P}{S}+1)\times(\frac{H_1-F+2P}{S}+1)\times K$
    - In the output volume, the $d^{th}$ of $W_2\times H_2$ is the result of performing a valid convolution of the $d^{th}$ filter over the input volume with a stride $S$, and the offser by $d^{th}$ bias.
    ---
    ==Pool==
    - Accept a volume of size $W_2\times H_2\times K$
    - Requires 2 hyperparameters
      - pooling kernel' size $F$
      - Stride $S$
    - Number of weights $0$
    - Produce a volume of size $(\frac{W_2-F}{S}+1)\times(\frac{H_2-F}{S}+1)$
    - It is not common to use zero padding for pooling layer.

!!! p "common setting"
    $K$ 2 çš„å¹‚
    F3S1P1, F5S1P2, F5S2P(whatever fits),F1S1P0

## Introduction

**Inï¼š** Vision Taskï¼Œå°±æ˜¯**é’ˆå¯¹å›¾åƒè¿™ä¸€ç‰¹æ®Šç»“æ„**ï¼ŒåŒ…æ‹¬å›¾ç‰‡åˆ†ç±», Object Detection ç›®æ ‡æ£€æµ‹ï¼Œè¾¹ç¼˜æ£€æµ‹, Object Segmentation ç›®æ ‡æå–ï¼Œå›¾ç‰‡é£æ ¼è¿ç§»ï¼Œ Image Captioning çœ‹å›¾è¯´è¯, Retrieval æ¢å¤å›¾ç‰‡â€¦

å…³äºå¤„ç†çš„å›¾ç‰‡å¯¹è±¡ï¼Œæœ‰å•çº¯åŸºäº **é»‘ç™½ç…§ç‰‡ç°åº¦å›¾åƒ(widthâœ–ï¸height)** çš„å·ç§¯ï¼Œä¹Ÿæœ‰åŸºäº **å½©è‰²ç…§ç‰‡ç«‹ä½“RGB(widethâœ–ï¸heightâœ–ï¸depth\channel)** çš„å·ç§¯

!!! p ""
    <u>CNNÂ is a sequence ofÂ Convolution Layers, interspersed with activation functions</u>.
    <div class="grid" markdown>
    <p>CNN is proposed toÂ reduceÂ the number of parameters, preserveÂ the image layout information, and make the networkÂ deeper </p>
    <figure markdown="span">![](./pics/CNN_22.png){width=80%}</figure>
    </div>

!!! p "å’Œå…¨è¿æ¥ç›¸æ¯”è¾ƒï¼Œå…¨è¿æ¥çš„å‚æ•°æ•°é‡è¾ƒå¤šï¼ˆä¸¤å±‚ä¹‹é—´çš„ç¥ç»å…ƒéœ€è¦ä¸¤ä¸¤ç›¸è¿ï¼‰ï¼Œå·ç§¯ç¥ç»ç½‘ç»œçš„å‚æ•°è¾ƒå°‘ï¼Œä¸»è¦æ˜¯ç”±äºæƒå€¼å…±äº«å’Œç¨€ç–è¿æ¥ã€‚"

![](./pics/CNN_1.png){width=80%}
![](./pics/CNN_2.png){width=80%}
![](./pics/CNN_3.png){width=80%}
![](./pics/CNN_4.png){width=80%}

1. The input of image data into the convolution neural network is processed with the help of pixel values of the image in the convolution layer.
2. ==Filters== are generated that perform convolutions over the entire image and train the network to identify and learn features from images, which are converted to matrices.
3. ==Batch== normalization of input vectors is performed at each layer, so as to ensure all input vectors are **normalized** and hence regularization in the network is attained.
4. The convolutions are performed until better accuracy has been attained and maximum feature extraction is done.
5. Convolutions result in the **sub-sampling** of images and the dimensions of input get changed according to ==padding== and ==stride== chosen.
6. Each convolution follows the ==activation layer(ReLU)== and ==pooling layer==, which brings in **non-linearity** and helps in **sub-sampling** respectively.
7. After the final convolution, the input matrix is converted to feature vectors. This feature vector is the ==flattened layer==.
8. Feature vector serves as input to the next layer(fully connected layer), where all features are collectively transferred into this network. ==Dropout== of random nodes occurs during training to reduce overfitting in this layer.
9. Finally, the raw values which are predicted output by the network are converted to probabilistic values with the use of ==softmax function==.

## Keywords

==å…±äº«æƒé‡==, ==å±€éƒ¨æ„ŸçŸ¥åŸŸ & ç¨€ç–è¿æ¥==,==Spatial Information==

### Shared Weightsï¼Œå…±äº«æƒé‡

åŒä¸€ä¸ªfilteråœ¨è¾“å…¥çŸ©é˜µä¸­è¿›è¡Œæ‰«æ

ä¸€ä¸ªéšè—å±‚ä¸­çš„æ‰€æœ‰**ç¥ç»å…ƒéƒ½æ£€æµ‹åœ¨å›¾åƒçš„ä¸åŒä½ç½®å¤„çš„åŒä¸€ä¸ªç‰¹å¾ã€‚æƒé‡å…±äº«ï¼Œåˆ™æ£€æµ‹ç‰¹å¾ç›¸åŒã€‚** å› æ­¤ä¹Ÿå°†ä»è¾“å…¥å±‚åˆ°éšè—å±‚çš„è¿™ç§æ˜ å°„ç§°ä¸º<u>ç‰¹å¾æ˜ å°„ï¼Œfilters, kernels</u>ã€‚è¯¥ç‰¹å¾æ˜ å°„çš„æƒé‡ç§°ä¸º**å…±äº«æƒé‡**ï¼Œå…¶åç½®ç§°ä¸ºå…±äº«åç½®ã€‚

### Local Receptive Fields & Sparse Connectivity, å±€éƒ¨æ„ŸçŸ¥åŸŸ & ç¨€ç–è¿æ¥

For convolution with kernel sizeÂ $K$, each element in the output depends on aÂ $K\times K$Â receptive field in the input.
Each successive convolution contains multiple regions from the previous one.
è¾“å‡ºçŸ©é˜µä¸­çš„æ¯ä¸€ä¸ªæ•°å€¼åªç”±è¾“å…¥æ•°æ®çš„ä¸€éƒ¨åˆ†è®¡ç®—å¾—æ¥ã€‚ä¸å¸¸è§„ç¥ç»ç½‘ç»œä¸€æ ·ï¼Œè¾“å…¥å±‚çš„ç¥ç»å…ƒéœ€è¦å’Œéšè—å±‚çš„ç¥ç»å…ƒè¿æ¥ã€‚ä½†è¿™é‡Œ**ä¸æ˜¯å°†æ¯ä¸€ä¸ªè¾“å…¥ç¥ç»å…ƒéƒ½ä¸æ¯ä¸€ä¸ªéšè—ç¥ç»å…ƒè¿æ¥**ï¼Œè€Œæ˜¯ä»…ä»…åœ¨ä¸€ä¸ªå›¾åƒçš„**å±€éƒ¨åŒºåŸŸåˆ›å»ºè¿æ¥**

![](./pics/CNN_5.png){width=60%}
![](./pics/CNN_6.png){width=60%}

### Spatial Information

è¾“å…¥å±‚ï¼š**äºŒç»´çŸ©é˜µæ’åˆ—**çš„**ç¥ç»å…ƒ**ã€‚

## Structure

![](./pics/CNN_21.png){width=80%}

### Input Layer

**äºŒç»´çŸ©é˜µæ’åˆ—**çš„**ç¥ç»å…ƒ**ã€‚

### Convolution Layers, Conv

!!! p "Convolve the filter with the image $\Rightarrow$ <u>slide over the image spatially, computing dot products</u>"

å®Œæˆå›¾åƒå’Œfilter çš„å·ç§¯å°±æ˜¯

1. ç”¨ä¸€ä¸ªå°å°çš„ $F\times F\times D$ shared filter åœ¨$N\times N\times D$ å›¾åƒä¸Š slide spatially, ç©ºé—´æ„ä¹‰ä¸Šåœ°æ»‘åŠ¨ã€‚
2. æ»‘åŠ¨çš„æ—¶å€™ï¼Œæ¯ä¸€æ¬¡æ¡†å®šçš„**å°å°å¯¹åº”å°ºå¯¸** $F\times F\times D$ å— chunk of the image, Local Receptive Fieldsï¼Œå’Œ $F\times F\times D$ shared filter åš dot product ==element-wise multiplication==ï¼Œ.

    !!! danger ""
        Dä¸ª channelï¼Œéƒ½è¦åˆ†åˆ«å’Œè¾“å…¥çš„Dä¸ªchannel åšå·ç§¯ï¼Œå¾—åˆ°Dä¸ªç‰¹å¾å›¾ï¼Œç„¶å**é€šé“èåˆ, sum all the (weights x inputs) of D channels**
3. å°†æ‰€æœ‰æ»‘åŠ¨çš„åˆ°çš„ç»“æœæŒ‰ç©ºé—´é¡ºåºé‡æ–°æ‹¼æˆ: $(N-F+1)\times(N-F+1)\times \red{1}$ tensor
4. å†åŠ ä¸Š $(N-F+1)\times(N-F+1)\times \red{1}$ shared bias åç½®

ä»¥ä¸Šæ˜¯åšä¸€ä¸ªfilterçš„è¿‡ç¨‹ã€‚$w^Tx+b$ã€‚
å› ä¸º input image å’Œ filter çš„ä¹˜æ³•æ˜¯ ==element-wise multiplication==ï¼Œå°±å’Œå‘é‡ç‚¹ç§¯ä¸€æ ·ï¼Œæ‰€ä»¥å¯ä»¥æƒ³è±¡ä¸ºå¤šç»´çš„ chunk å’Œ filter å’Œ bias å±•å¹³æˆå‘é‡ï¼Œ$\R^{F\times F\times D}\xrightarrow{\text{Flatten}}\R^{F^2D\times 1}\xrightarrow{\text{dot product}}\R$

$K$ ä¸ª filters å°±æœ‰ $K$ ä¸ª tensorï¼Œæœ€å **stack å †å ** these up to get a new â€œimage tensorâ€==activation map== of size as the input of the next layer. ç«‹ä½“å·ç§¯çš„è¾“å‡ºç»“æœçš„ç»´åº¦ï¼Œé•¿å’Œå®½å’Œä¹‹å‰ç°åº¦å›¾åƒçš„è®¡ç®—ä¸€æ ·ï¼Œè€Œ**ç»“æœçš„é€šé“æ•°åˆ™ç”±è¿‡æ»¤å™¨çš„ä¸ªæ•°å†³å®š**
$$(N-F+1)\times(N-F+1)\times \red{K}$$

<div class="grid" markdown>
<figure markdown="span">![](./pics/CNN_7.jpeg){width=90%}<p>å¹³é¢çš„ï¼Œe.g.ï¼š**é»‘ç™½ç…§ç‰‡ç°åº¦å›¾åƒ**</p></figure>
<figure markdown="span">![](./pics/CNN_8.png)<p>ç«‹ä½“çš„ï¼Œe.gï¼š**å½©è‰²ç…§ç‰‡ç«‹ä½“RGBå›¾åƒ**</p></figure>
</div>

- ç«‹ä½“çš„ï¼Œe.gï¼š**å½©è‰²ç…§ç‰‡ç«‹ä½“RGBå›¾åƒ**
è¿‡æ»¤å™¨æ˜¯ä¸€ä¸ªç«‹æ–¹ä½“ï¼Œåœ¨è¾“å…¥æ•°æ®ä¸Šæ‰«æï¼Œæ¯ä¸€ä¸ªé€šé“çš„æƒé‡åˆ†åˆ«ä¸è¾“å…¥å›¾ç‰‡çš„æ¯ä¸€ä¸ªé€šé“æ‰«æåˆ°çš„å€¼ç›¸ä¹˜å†åŠ å’Œå¾—åˆ°è¾“å‡ºçŸ©é˜µä¸Šçš„ä¸€ä¸ªè¾“å‡ºå€¼

<figure markdown="span">![](./pics/CNN_9.png){width=90%}<p>ç«‹ä½“çš„ï¼Œe.gï¼š**å½©è‰²ç…§ç‰‡ç«‹ä½“RGBå›¾åƒ**</p></figure>

<figure markdown="span">![](./pics/CNN_10.png){width=90%}<p>ç«‹ä½“çš„ï¼Œe.gï¼š**å½©è‰²ç…§ç‰‡ç«‹ä½“RGBå›¾åƒ**</p></figure>

### Filters, Kernels

!!! p "Input ImageÂ xÂ Â Feature DetectorÂ =Â ==Feature Map=="

#### about Size

1. always **extend the full depth o**f the input volumeï¼Œ ä¸€ä¸ª filter çš„æ·±åº¦(é€šé“æ•°)è¦å’Œ input çš„æ·±åº¦(é€šé“æ•°)ä¸€æ ·ï¼Œä½†æ˜¯è¾“å‡ºä»åªæœ‰ä¸€ä¸ªé€šé“æ•°ã€‚
    $$18=\cfrac{32-5}{1}+1, 30=\cfrac{32-3}{1}+1$$

    ```mermaid
    graph LR
    A[Input<br>32âœ–ï¸32âœ–ï¸<FONT COLOR="#ff0000">3</FONT>]
    B{Filter<br>5âœ–ï¸5âœ–ï¸<FONT COLOR="#ff0000">3</FONT>}
    C{Filter<br>3âœ–ï¸3âœ–ï¸<FONT COLOR="#ff0000">3</FONT>}
    A --> B
    A --> C
    D{Stride<br>1}
    B --- D
    C --- D
    E[Output<br>18âœ–ï¸18âœ–ï¸<FONT COLOR="#ff0000">1</FONT>]
    F[Output<br>30âœ–ï¸30âœ–ï¸<FONT COLOR="#ff0000">1</FONT>]
    D --> E
    D --> F
    ```

    ![](./pics/CNN_11.png){width=60%}

2. dim of **filter ä¸€èˆ¬ä¸ºå¥‡æ•°ï¼Œè‹¥ä¸ºå¶æ•°ï¼Œåˆ™ä¼šäº§ç”Ÿä¸å¯¹ç§°å¡«å……**
3. **1âœ–ï¸1 Convolution** is meaningful!
It computes the dot product over the channels.

<figure markdown="span">![](./pics/CNN_13.png){width=60%}<p>1âœ–ï¸1 Convolution</p></figure>

**advantagesï¼š**

- Shrinking too volumes spatially
  
    !!! danger "Shrinking too fast is not good,"

æ¯”å¦‚è¯´CNNï¼ŒCNNæ˜¯ç”¨å·ç§¯æ ¸å’Œæ„Ÿå—é‡åšè¿ç®—ï¼Œæ¯ä¸€ä¸ªæ–°äº§ç”Ÿç‰¹å¾æ•°ï¼Œä¹Ÿå°±æ˜¯ output çš„ä¸€ä¸ªå°å°çš„æ•°å­—ï¼Œå›Šæ‹¬çš„ä¹Ÿåªæ˜¯ä¸€ä¸ªå°å°çš„æ„Ÿå—é‡çš„ä¿¡æ¯ã€‚å¯¹ä¸€ä¸ªkernel æ¥è¯´ï¼Œè™½ç„¶ output æ˜¯ç”±æ‰€æœ‰çš„æ„Ÿå—é‡ of input å·ç§¯ä¹‹åå †å è€Œæˆçš„ä¸€ä¸ª [L, W]çŸ©é˜µï¼Œä¹Ÿå°±æ˜¯è¿™ä¸€ä¸ª kernel å’Œæ‰€æœ‰çš„æ„Ÿå—é‡åšè¿ç®—çš„ç»“æœå †å è€Œæˆã€‚ä½†æ˜¯ **ç®€å•å±€éƒ¨ç‰¹å¾å †å ä¸ç­‰äºå…¨å±€ç‰¹å¾ã€‚** è¿™ä¹Ÿæ˜¯CNNç¨€ç–é“¾æ¥çš„ç‰¹ç‚¹ã€‚

æ‰€ä»¥æˆ‘ä»¬å¸¸è¯´CNNå¯¹äºé‚£ç§é•¿åºåˆ— long sequence input ä¸å¤ªå‹å¥½ï¼Œå› ä¸ºå¯¹äºä¸¤ä¸ªé—´éš”æ¯”è¾ƒè¿œçš„ pixels æ¥è¯´ï¼Œè¦æ˜¯æƒ³è·å¾—ä»–ä»¬ä¹‹é—´çš„å…³ç³»ç‰¹å¾ï¼Œå°±éœ€è¦å †å å¾ˆå¤šä¸ªå·ç§¯å±‚ï¼Œæ‰èƒ½è·å¾—ä»–ä»¬çš„å…³ç³»ç‰¹å¾ã€‚

![](./pics/CNN_25.png){width=60%}

#### about Stride sï¼šç§»åŠ¨çš„æ–¹æ ¼

1. s = 1 ï¼ˆdefaultï¼‰
2. **do not want to capture all the data** or information available so we skip some.
3. è®¾ç½®çš„ stride è¦è¢«åˆšå¥½è®¾ç½®çš„filterå·ç§¯åˆ°$$\red{\text{Output Size }(\cfrac{N-F}{s}+1)\times(\cfrac{N-F}{s}+1) }, \quad\cfrac{N-F}{\text{stride}}\in Z $$

    ![](./pics/CNN_12.png){width=40%}

**drawbacksï¼š**

- lose data over borders å®¹æ˜“ä¸¢å¤±è¾¹ç¼˜æˆ–è€…æ˜¯è§’è½ä¸Šçš„åƒç´ ä¿¡æ¯ï¼Œè­¬å¦‚æ‰€å½“ stride=1 çš„æ—¶å€™ï¼Œè¾¹è¾¹å°±å‡ºç°ä¸€éï¼Œä¸­é—´çš„éƒ¨åˆ†ä¼šåœ¨æ»‘åŠ¨çš„æ—¶å€™overlap åˆ°ï¼Œå‡ºç°æ¬¡æ•°å°±ä¼šé‡å¤ï¼Œè¿™ä¹Ÿä½“ç°äº†ä¸€ç§è®¾å®šï¼šå›¾åƒä¸­é—´æ€»æ˜¯æ¯”è¾ƒé‡è¦ï¼Œæ‰¿è½½æ›´å¤šä¿¡æ¯

**advantagesï¼š**

1. è¾“å‡ºçš„å›¾ç‰‡ä¼šç¼©å°

#### about Padding

- ä¸ºä»€ä¹ˆè¦padï¼Ÿ
ä¸ºäº†è§£å†³å®¹æ˜“ä¸¢å¤±è¾¹ç¼˜æˆ–è€…æ˜¯è§’è½ä¸Šçš„åƒç´ ä¿¡æ¯ã€‚padä¹‹åæœ¬æ¥è¾¹ç¼˜çš„éƒ¨åˆ†å°±ä¸ä¼šåªå‡ºç°ä¸€æ¬¡ã€‚ $\impliedby$<u>convolved ä¹‹å‰ pad</u>. Due to padding, information on the borders of images is also preserved similarly to at the centre of images.
- åœ¨å“ªé‡Œpadï¼Ÿ pad çš„èŒƒå›´å¤šå¤§
  - To è§£å†³è¾¹ç¼˜å®¹æ˜“ä¸¢å¤± $\implies$ <u>on the boundary</u>, image çš„å››å‘¨éƒ½è¦ pad. èŒƒå›´è‡ªå®šä¹‰, **pad with p-pixel border**
  - To **å·ç§¯å‰åå¤§å°ä¸å˜**ï¼Œ==$p=\cfrac{F-1}{2}\:\text{when s=1}$==
    $p=\cfrac{N(s-1)+F-s}{2}$

**ä¿è¯å·ç§¯å‰åçš„ç»´åº¦ä¸å˜ï¼Œ**

- proof of  formula of p **æ­¤å¤„stride=1ï¼ˆdefaultï¼‰**

    $N= N+2p-F+1\implies p=\cfrac{F-1}{2}$
- pad ä»€ä¹ˆï¼Ÿ
<u>pad 0</u> on the boundaryï¼Œå› ä¸ºåšçš„æ˜¯ dot productï¼Œä¸ä¼šå½±å“ç»“æœ

$$\begin{align*}
\text{Output Size without padding}&=(\cfrac{N-F}{s}+1)\times(\cfrac{N-F}{s}+1)\\  
\text{Output Size with padding}&=(\cfrac{N+2p-F}{s}+1)\times(\cfrac{N+2p-F}{s}+1)
\end{align*}$$

![](./pics/CNN_16.png){width=60%}

#### about Meaning

1. åŒä¸€å¼ ç‰¹å¾å›¾ï¼ŒåŒä¸€ä¸ªé€šé“ï¼Œä¸Šçš„æ‰€æœ‰å…ƒç´  (ç¥ç»å…ƒ) éƒ½æ˜¯å¯¹å›¾åƒçš„ä¸åŒä½ç½®çš„åŒä¸€ä¸ªç‰¹å¾çš„æ£€æµ‹ï¼Œé€šé“ä¸­æŸä¸€å¤„ (ç‰¹å¾å›¾ä¸ŠæŸä¸€ä¸ªç¥ç»å…ƒ) æ•°å€¼çš„å¤§å°å°±æ˜¯å½“å‰ä½ç½®å¯¹å½“å‰ç‰¹å¾å¼ºå¼±çš„ååº”ã€‚
2. ä¸€ä¸ª filter å°±æ˜¯ä¸€ä¸ªç‰¹å¾ï¼Œæ¯ä¸ª filter ä½“ç°çš„ç‰¹è´¨éƒ½ä¸ä¸€æ ·ã€‚
ä¸ºäº†ä½¿å¾—æ¨¡å‹å°†æ³¨æ„åŠ›é›†ä¸­äºå›¾ç‰‡çš„æŸäº›ä½ç½®ï¼Œ**è€Œåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ›´å¥½çš„æ–¹æ³•æ˜¯å°†è¿‡æ»¤å™¨é‡Œé¢çš„å€¼è®¾ç½®æˆå‚æ•°ï¼Œè®©æ¨¡å‹é€šè¿‡åå‘ä¼ æ’­å»å­¦ä¹ åˆ°è¿‡æ»¤å™¨ä¸­çš„æƒé‡å€¼**ï¼Œä»£æ›¿äººä¸ºçš„è®¾å®šã€‚

<div class="grid" markdown>
<figure markdown="span">![](./pics/CNN_14.png)<p>yellow</p></figure>
<figure markdown="span">![](./pics/CNN_15.png)<p>roll</p></figure>
</div>

1. <u>ç«‹ä½“çš„ filter</u>ï¼Œæ¯ä¸€ä¸ªé€šé“çš„æƒé‡åˆ†åˆ«å¯¹åº”è¾“å…¥å›¾ç‰‡çš„æ¯ä¸€ä¸ªé€šé“ã€‚**å¯ä»¥é€šè¿‡è®¾ç½®è¿‡æ»¤å™¨ä¸åŒé€šé“çš„æƒå€¼æ¥å…³æ³¨äºåŸå§‹å›¾ç‰‡ä¸åŒé€šé“çš„å†…å®¹**

### Batch Normalization

Batch normalization is generally done in between convolution and activation(ReLU) layers. It normalizes the inputs at each layer, reduces internal co-variate shift(change in the distribution of network activations) and is a method to regularize a convolutional network.

Batch normalizing allows higher learning rates that can reduce training time and gives better performance. It allows learning at each layer by itself without being more dependent on other layers. Dropout which is also a regularizing technique, is less effective to regularize convolution layers.

### Activation function

å·ç§¯æ“ä½œåªæ˜¯åŠ æƒæ±‚å’Œçš„çº¿æ€§æ“ä½œï¼Œè‹¥ç¥ç»ç½‘ç»œåªç”¨å·ç§¯å±‚ï¼Œé‚£ä¹ˆæ— è®ºæœ‰å¤šå°‘å±‚ï¼Œè¾“å‡ºéƒ½æ˜¯è¾“å…¥çš„çº¿æ€§ç»„åˆï¼Œç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›æœ‰é™ï¼Œæ— æ³•å­¦ä¹ åˆ°éçº¿æ€§å‡½æ•°ã€‚å› æ­¤ CNN å¼•å…¥æ¿€åŠ±å‡½æ•°ï¼Œæ¿€æ´»å‡½æ•°æ˜¯ä¸ªéçº¿æ€§å‡½æ•°ï¼Œå¸¸ä½œç”¨äºå·ç§¯å±‚å’Œå…¨è¿æ¥å±‚è¾“å‡ºçš„æ¯ä¸ªç¥ç»å…ƒï¼ˆåˆ†é‡/å…ƒç´ ï¼‰ï¼Œç»™ç¥ç»å…ƒå¼•å…¥äº†éçº¿æ€§å› ç´ ï¼Œä½¿ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›æ›´å¼ºï¼Œå‡ ä¹å¯é€¼è¿‘ä»»æ„å‡½æ•°ï¼Œè¿™æ ·ç¥ç»ç½‘ç»œå°±å¯åº”ç”¨åˆ°ä¼—å¤šçš„éçº¿æ€§æ¨¡å‹ä¸­ã€‚

### Pooling Layer, æ± åŒ–å±‚

a ==down-sampling== strategy
1. Construct better translationally invariant features. å±€éƒ¨å¹³ç§»ä¸å˜æ€§ï¼Œå½“è¾“å…¥æœ‰ä¸€å®šçš„å¹³ç§»æ—¶ï¼Œç»æ± åŒ–åè¾“å‡ºä¸ä¼šå‘ç”Ÿæ”¹å˜ã€‚ä½¿å¾—å…¶ç‰¹å¾æå–ä¸ä¼šå› ä¸ºç›®æ ‡ä½ç½®çš„å˜åŒ–è€Œå—åˆ°è¾ƒå¤§çš„å½±å“
2. Learn more compact features. å°†æŸä¸ªå…ƒç´ é‚»åŸŸçš„**æ€»ä½“ç»Ÿè®¡**ç‰¹å¾ä½œä¸ºç½‘ç»œåœ¨è¯¥ä½ç½®çš„è¾“å‡º we are taking **a summarized value** over all the values present !!! controls overfitting
3. ç¼©å‡æ¨¡å‹çš„å¤§å°ï¼Œç®€åŒ–å·ç§¯å±‚çš„è¾“å‡º
4. æé«˜è®¡ç®—é€Ÿåº¦ä»¥åŠæé«˜æ¨¡å‹çš„é²æ£’æ€§ç­‰ã€‚
5. **æ²¡æœ‰éœ€è¦å­¦ä¹ çš„å‚æ•°ï¼Œåªéœ€è¦å®šä¹‰è¿‡æ»¤å™¨çš„å¤§å°ä»¥åŠæ­¥é•¿å³å¯**

!!! p "The Dimension After Pooling"
    Given aÂ $M\times N\times D$Â tensor, if we apply the pooling operator with sizeÂ $K\times K$Â and StrideÂ $p$ , what are the dimensions of the output?
    - depth has no change
    - åœ¨widthå’Œheighté‚£é‡Œå°±åƒå·ç§¯ä¸€æ · $\text{without padding}=(\frac{N-F}{s}+1)\times(\frac{N-F}{s}+1)$
    - $\implies (\cfrac{M-K}{p}+1)\times (\cfrac{N-K}{p}+1)\times D$

|Pooling stategies||
|--|--|
|**Max Pooling**|ï¼ˆè¾ƒå¸¸ç”¨ï¼‰is robust to small perturbations.ç›´è§‚ç†è§£æ˜¯èƒ½å¤Ÿæå–å‡ºè¾“å…¥å›¾ç‰‡ä¸­æ¯”è¾ƒæ˜¾è‘—çš„ç‰¹å¾
**Average Pooling**|idk

<figure markdown="span">![](./pics/CNN_17.png){width=60%}<p>yellow</p></figure>

### Flatten Layer â€” Tensor Reshape

<div class="grid" markdown>
<figure markdown="span">![](./pics/CNN_18.png){width=60%}</figure>
<p>the output feature map(matrix) will be converted into vector<br> å°†å‰é¢å·ç§¯å±‚æˆ–æ± åŒ–å±‚è¾“å‡ºçš„æ‰€æœ‰äºŒç»´ç‰¹å¾å›¾ä¸€èµ·æ˜ å°„æˆ1ä¸ªä¸€ç»´çš„ç‰¹å¾å‘é‡</p>
</div>

### Fully- Connected Layer, FC

å…‰å·ç§¯æ˜¯ä¸èƒ½å®Œæˆåˆ†ç±»ä»»åŠ¡çš„ï¼Œæ‰€ä»¥å°±æ˜¯è¦åé¢è¿Â FCå±‚ï¼Œèµ·åˆ°â€œåˆ†ç±»å™¨â€çš„ä½œç”¨
**ä¸­é—´å¯èƒ½æœ‰å¤šä¸ªFCå±‚ï¼Œ**æœ€åæ¨¡å‹è¾“å‡ºä¸€ä¸ª**ç»´åº¦ç­‰äºç±»åˆ«æ•°ï¼ˆè¾“å‡ºçš„ç¥ç»å…ƒä¸ªæ•°ï¼‰**çš„**å‘é‡**

<div class="grid" markdown>
<figure markdown="span">![](./pics/CNN_19.png){width=60%}</figure>
<figure markdown="span">![](./pics/CNN_20.png){width=60%}</figure>
</div>

### softmax

softmaxå½’ä¸€åŒ–ï¼Œè¡¨ç¤ºæ¯ä¸€ç±»çš„æ¦‚ç‡ï¼Œç„¶å**å°†å¾—åˆ†æœ€é«˜çš„ç±»åˆ«åˆ¤ä¸ºè¾“å…¥çš„ç±»åˆ«**
The softmax function is used to map the non-normalized output of a network to a probability distribution.
è½¯æœ€å¤§å‡½æ•°ç”¨äºå°†ç½‘ç»œçš„éè§„èŒƒåŒ–è¾“å‡ºæ˜ å°„åˆ°æ¦‚ç‡åˆ†å¸ƒã€‚

## Famous CNN Architectures

### Deeper or Wider?

**Deep CNN**ï¼šDeeply stacked  Convolution Neural Network

|  | LeNet-5 | AlexNet | VGG Net | ResNet |GoogLeNet
| --- | --- | --- | --- | --- | --- |
| Key | ç‰¹å¾ç¨€ç–é“¾æ¥ | Relu activation  | smaller filters | ^ |
| Activation | Sigmoid | ReLU |  ^|^  |
| Advantages | basic architecture
å¥ å®šåŸºç¡€ | GPU | ^ |^  |
| Drawbacks | ç®—åŠ›ä¸å¤Ÿ |^  |  |  |
| è®¾è®¡ç”¨é€” | æ‰‹å†™æ•°å­—è¯†åˆ« | ImageNet classification with deep convolutional neural networks â€“ NIPS 2012 | Very Deep Convolutional Networks for Large-Scale Image Recognition â€“ ICLR 2015 |  Deep Residual Learning for Image Recognition â€“ CVPR 2016|Going deeper with convolutions â€“ CVPR 2015
| deep CNN |  |  â˜‘ï¸|â˜‘ï¸  |â˜‘ï¸  |

!!! p "The Skip-connection was first proposed in ResNet"

### **LeNet-5**

**7 Layers**Â (input layer not counted)

**3 Convolution Layers**Â (C1; C3; C5)

**2 Pooling Layers**Â (S2; S4) â€” Mean

**2 Fully Connected Layers**Â (F6; Output)

**Sigmoid Activation!**

Detailsï¼š

1. subsampling ä¸­ä¼šåœ¨ç»“æœä¸Šå¤šåŠ ä¸€ä¸ªåç½®é¡¹
2. S2-C3 sparse connected ç”Ÿæˆçš„16@feature mapåˆ†åˆ«æŒ‰ç›¸é‚»3ä¸ªï¼Œç›¸é‚»4ä¸ªï¼Œéç›¸é‚»4ä¸ªå’Œå…¨éƒ¨6ä¸ªç‰¹å¾å›¾è¿›è¡Œfeature mappingã€å› ä¸ºç®—åŠ›ä¸è¶³ï¼Œé™åˆ¶äº†è¿æ¥æ•°ï¼Œå‡å°‘è®¡ç®—å¼€é”€ï¼›è¿™æ ·ä¸åŒç‰¹å¾å›¾çš„ç»„åˆå¯ä»¥ä½¿æ–°ç”Ÿæˆçš„feature map å­¦åˆ°ä¸åŒçš„ç‰¹å¾æ¨¡å¼ ã€‘
3. MLPä½œä¸ºåˆ†ç±»å™¨
4. è¿™é‡Œçš„ faltten æ˜¯ç”¨CNN

### AlexNet

ReLU, max pooling, stride
Data augmentation
Optimizer parameters

### VGG Net

**152 layersÂ for ImageNet.**

ğŸ’¡ **Key Idea of VGG**: Replace the large convolution filter by stacking some **smaller convolution filters.**

1. **More concise and generalizable.**
2. **Smaller filters can achieve better performance than larger filters. smaller filters å †ç§¯å¯ä»¥æ¯” largeræ›´é«˜**

3. **Demonstrate that increase depth can boost performance. æ·±åº¦å¯æé«˜è¡¨ç°**

5x5 conv = two 3x3 conv
7x7 conv = three 3x3 conv

### Residual Net, **ResNet**

keep origin information

Skip-connection
Batch-normalization
Bottleneck block

### **Dense Net**

### **GoogleNet**

There are some parallel polar level.
Okay? Blocks in in a certain layer that means You will send. You will
send I input. Okay, into different convolutions. Okay. And let's go
through different architectures. And then we merged guys okay, into a
final okay output. Okay, So this is a key idea. Okay, significant
difference. Okay, of Google, net with different, other, different neural
networks. Okay. But yeah you can try this. Okay. But we will not Talk
about the details of this neural networks, Okay

### Light-weight networks
!!! p "Performance on computation limits"

![](./pics/CNN_23.png){width=60%}
![](./pics/CNN_24.png){width=60%}

!!! danger "a depthwise convolution involves applying a separate 3x3 filter to each input channel."
    > > For a depthwise 3x3 convolution, the number of  input channels and output channels are both 32, how many parameters does this convolution layer have ï¼Ÿ
    >
    > $3*3*32$

**Group convolution:**

## Practical Exercise

## Parameters Initialization

å¿«é€Ÿ shrikage to point

## Bach Normalization

## Application

## Edge Detection

å¦‚ä¸Šå›¾æ‰€ç¤ºï¼šè¾“å…¥æ˜¯ä¸€ä¸ª6*6çš„çŸ©é˜µï¼Œè¾“å…¥æ˜¯ä¸€ä¸ªå·¦ç™½å³ç°çš„å›¾ç‰‡ï¼ˆç™½è‰²éƒ¨åˆ†å¯¹åº”çš„çŸ©é˜µå€¼å¤§äº0ï¼Œç°è‰²éƒ¨åˆ†çš„å€¼ä¸º0ï¼‰ï¼Œä¸­é—´æœ‰ä¸€é“ç«–çº¿åˆ†å‰²ï¼›ä¸­é—´çš„å‚ç›´è¿‡æ»¤å™¨æ˜¯ä¸€ä¸ª3*3çš„çŸ©é˜µï¼Œç”±ç™½ç°é»‘ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼ŒçŸ©é˜µä¸‰åˆ—çš„å€¼åˆ†åˆ«å¤§äº0ï¼Œç­‰äº0å’Œå°äº0ï¼›è¾“å‡ºçš„ç»“æœçŸ©é˜µä¸­ï¼Œä¸­é—´çš„ä¸¤åˆ—å¤§äº0ï¼Œå³è¾“å‡ºçš„å›¾ç‰‡ä¸­é—´éƒ¨åˆ†ä¸ºç™½è‰²ï¼Œä¹Ÿå°±æ˜¯è¯´ç»è¿‡å·ç§¯ä¹‹åï¼ŒæˆåŠŸçš„æ£€æµ‹å‡ºäº†åŸå§‹å›¾ç‰‡ä¸­é—´å­˜åœ¨çš„å‚ç›´ç«–çº¿ã€‚

## Exercise

> >(in L5 in AMA564), input $\in\R^{5\times5}$,kernel $\in\R^{3\times3}$,bias=-500, activation function is ReLU

## code

[å·ç§¯ç¥ç»ç½‘ç»œï¼ˆæµ…æ˜¾æ˜“æ‡‚ï¼‰-å´æ©è¾¾è¯¾ç¨‹å­¦ä¹ ]: https://zhuanlan.zhihu.com/p/35251749/

[ç¥ç»ç½‘ç»œåŠCNNä¸­çš„é€šé“ã€å…±äº«æƒé‡ã€ç‰¹å¾æ˜ å°„ç­‰çš„ç†è§£_zhu_Lydiaçš„åšå®¢-CSDNåšå®¢_cnnçš„é€šé“]:https://blog.csdn.net/zhu_Lydia/article/details/88567648

[Convolutional Neural Network Architecture | CNN Architecture]:https://www.analyticsvidhya.com/blog/2020/10/what-is-the-convolutional-neural-network-architecture/

[Convolutional Neural Network | Deep Learning | Developers Breach]: https://developersbreach.com/convolution-neural-network-deep-learning/
