# math

## logrithm

åœ¨æ•°æ®å¤„ç†ä¸­ï¼Œç»å¸¸ä¼šæŠŠåŸå§‹æ•°æ®å–å¯¹æ•°ä¹‹åå†å¤„ç†ï¼Œæ— è®ºæ˜¯åœ¨ç”»å›¾ï¼Œè¿˜æ˜¯åœ¨ da é‡Œã€‚
è®“æˆ‘å€‘åœ¨è™•ç†**æŒ‡æ•¸ç´šå¢é•·çš„äº‹ç‰©æ™‚å…·æœ‰æ›´å¤§çš„éˆæ´»æ€§(å°æ•¸å¹«åŠ©æˆ‘å€‘è™•ç†â€œéç·šæ€§â€æ•¸æ“šã€‚)**ã€‚èˆ‡æ™®éçœ‹æ³•ç›¸åï¼ŒæŒ‡æ•¸å¢é•·ä¸¦ä¸ç¸½æ˜¯åƒä¸€æ£µæ¨¹é•·åˆ°å¤©ç©ºä¸€æ¨£â€”â€”**å®ƒåƒ…åƒ…æ„å‘³è‘—æ•¸æ“šä»¥ç›¸ç•¶æ†å®šçš„é€Ÿåº¦è¤‡åˆï¼ˆæˆ–è¡°æ¸›ï¼‰**

**ä¸ºä»€ä¹ˆèƒ½è¿™æ ·åšï¼š**<br>
log æ˜¯å•è°ƒå¢å‡½æ•°ï¼Œä¸ä¼šæ”¹å˜æ•°æ®çš„ç›¸å¯¹å…³ç³»ã€‚

**ä¸ºä»€ä¹ˆè¦è¿™æ ·åšï¼š**

- ç¼©å°æ•°æ®çš„ç»å¯¹æ•°å€¼, æ–¹ä¾¿è®¡ç®—ã€‚å°¤å…¶æ˜¯å¯¹ä¸€äº›ç›´æ¥è®¡ç®—ä¼šè¶…è¿‡å¸¸ç”¨æ•°æ®ç±»å‹çš„å–å€¼èŒƒå›´ã€‚
    > æ¯”å¦‚ TF-IDF è®¡ç®— åœ¨å¤§è§„æ¨¡é¢„æ–™ä¸­ï¼Œå¸¸ç”¨è¯çš„é¢‘ç‡ä¼šéå¸¸å¤§ (I, æˆ‘)
    !!! p ""
        å…¶å®å°±è·Ÿ åƒä¸‡çº§åˆ«çš„æ•°å­— é™¤ä»¥åƒä¸‡ï¼Œä» $x*{10}^7\xrightarrow{\div{10}^7}x$ï¼Œå°±å¯ä»¥åœ¨é»˜è®¤æ˜¯åƒä¸‡çº§åˆ«åªå¯¹åƒä¸‡ä½ä¸Šè¿›è¡Œå¤„ç†ã€‚log å°±æ˜¯å…¶ä¸­ä¸€ç§ç¼©å°æ•°æ®çš„ç»å¯¹æ•°å€¼çš„æ–¹æ³•è€Œå·²ï¼Œåªæ˜¯å®ƒæ›´æ“…é•¿å¤„ç†æ•°æ®ä¹‹é—´ç›¸å·®éå¸¸å¤§ï¼Œç±»æŒ‡æ•°å¢åŠ æˆ–è¡°å‡çš„è¶‹åŠ¿çš„é—´è·ã€‚
- å–å¯¹æ•°åï¼Œå¯ä»¥å°†ä¹˜æ³•è®¡ç®— $\rightarrow$ åŠ æ³•è®¡ç®—ï¼Œæ›´å®¹æ˜“ç†è§£å¤§å°å…³ç³»ã€‚
    !!! warning è¿™ä¸ªç‰¹åˆ«å¸¸è§åœ¨å›¾ç‰‡ä¸­ï¼ï¼ï¼

    ``` python title = volume of planets
    planets= {
        'sun': 1.41*10**18,
        'jupiter': 1.43*10**15
        'earth': 1.83*10**12,
        'moon': 2.20*10**10
    }
    ```

    <div class="grid" markdown>
    <figure markdown="span">![](./pics/log_1.png)<p>ä¸ç»è¿‡å¤„ç†ä¹‹å‰ï¼Œåªèƒ½çŸ¥é“ Sun æ˜¯ä¸€éª‘ç»å°˜çš„å¤§ï¼Œä½†æ˜¯è¿™ä¸ªä¸€éª‘ç»å°˜åˆ°åº•æ˜¯å¤šä¸€éª‘ç»å°˜ä¹Ÿä¸çŸ¥é“ï¼Œé™¤æ­¤ä¹‹å¤–å…¶å®ƒ items æ˜¯ä¸çŸ¥é“ç›¸å¯¹å¤§å°çš„ï¼Œæ‰€ä»¥ä¸å¥½ã€‚</p></figure>
    <figure markdown="span">![](./pics/log_2.png)<p>å¾ˆæ˜ç¡®çŸ¥é“ç›¸å¯¹å¤§å°å…³ç³»ï¼Œè€Œä¸”: Sun åœ¨ 18ï¼ŒJupiter åœ¨ 15ï¼Œä¸¤è€…ç›¸å·®äº†3ï¼Œå°±æ˜¯$10^3$ é‡çº§ã€‚</p></figure>
    <div>
    > æ¸¬é‡åœ°éœ‡å¼·åº¦ã€‚é€™è¢«ç¨±ç‚ºé‡Œæ°éœ‡ç´šï¼Œçµ¦å‡ºäº†ä»¥ 10 ç‚ºåº•çš„å°æ•¸çš„åœ°éœ‡å¼·åº¦ã€‚ 6.0ç´šåœ°éœ‡æ¯”5.0ç´šåœ°éœ‡å¼·10å€
- åœ¨æ•°å€¼å°çš„åœºæ™¯æ¯”æ•°å€¼å¤§çš„æ—¶å€™å¯¹å·®å¼‚æ›´æ•æ„Ÿã€‚æ˜¯ä¸€ä¸ªè¿™ç¬¦åˆæŸäº›åº”ç”¨åœºæ™¯ã€‚
    > å¯¹äºä»·æ ¼ï¼Œç™¾å…ƒä¸‹çš„å·®å‡ ç™¾ & åƒå…ƒçš„å·®å‡ ç™¾ ä¸æ˜¯ä¸€ä¸ªæ•æ„Ÿç¨‹åº¦ã€‚
    > å¯¹äºä¸­æ–‡åˆ†è¯ï¼Œèƒ½åˆ†æˆ $A_1(200) \& A_2(800)$ & $B_1(500) \& B_2(500)$ï¼Œå•çº¯æ¯”è¾ƒé¢‘ç‡å’Œéƒ½æ˜¯1000ï¼Œæ— æ³•è¾¨æ¸…ä¼˜åŠ£ã€‚ä½†æ˜¯æ¯”è¾ƒå¯¹æ•°å’Œ $\begin{cases}A=\log_{10}(200)+\log_{10}(800)\approx2.30103+2.90308\approx5.2\\B:2\log_{10}(500)\approx2*2.69897\approx5.4\end{cases}\implies B>A$ åå‘éƒ½æ˜¯å¸¸è§çš„æƒ…å†µï¼Œé€‰æ‹© B çš„æ–¹æ¡ˆã€‚
- æ‰€å¾—åˆ°çš„æ•°æ®æ˜“æ¶ˆé™¤å¼‚æ–¹å·®é—®é¢˜ã€‚ã€ä¸æ‡‚ã€‘
- åœ¨ç»æµå­¦ä¸­ï¼Œå¸¸å–è‡ªç„¶å¯¹æ•°å†åšå›å½’ï¼Œè¿™æ—¶å›å½’æ–¹ç¨‹ä¸º lnY=a lnX+b ï¼Œä¸¤è¾¹åŒæ—¶å¯¹Xæ±‚å¯¼ï¼Œ1/Y*(DY/DX)=a*1/X, b=(DY/DX)*(X/Y)=(DY*X)/(DX*Y)=(DY/Y)/(DX/X) è¿™æ­£å¥½æ˜¯å¼¹æ€§çš„å®šä¹‰ã€‚ã€ä¸æ‡‚ã€‘

!!! danger "å®è·µä¸­ï¼Œå–å¯¹æ•°çš„ä¸€èˆ¬æ˜¯æ°´å¹³é‡ï¼Œè€Œä¸æ˜¯æ¯”ä¾‹æ•°æ®ï¼Œä¾‹å¦‚å˜åŒ–ç‡ç­‰ã€‚"

!!! question "æ•°æ®é›†æœ‰è´Ÿæ•°ï¼Œå¯ä¸å¯ä»¥é€šè¿‡åŠ ä¸€ä¸ªåº•æ•°ï¼Œä½¿å¾—æ•´ä½“æ•°æ®ä¸ºæ­£å†log å¤„ç†"

!!! danger â€œå…³äºè¶‹åŠ¿çš„é”™è§‰ï¼šå¢åŠ é‡ & å¢é•¿é€Ÿç‡â€
    å¢åŠ é‡ $=Y-X$, å¢åŠ é€Ÿç‡ $=\cfrac{Y-X}{X}$
    å¢åŠ é‡å¤§ä¸ä»£è¡¨å¢åŠ é€Ÿç‡å¤§ï¼Œè€Œæ˜¯è¦è¿›è¡Œè®¡ç®—ã€‚é€šè¿‡ raw data æˆ‘ä»¬èƒ½æ„Ÿè§‰â€œé‡â€çš„å˜åŒ–ï¼Œé€šè¿‡ log data æˆ‘ä»¬èƒ½æ„Ÿåˆ°â€œé€Ÿç‡çš„å˜åŒ–â€ã€‚<br>
    $\begin{cases}x:=\log_{10}X\\y:=\log_{10}Y\end{cases}\implies \cfrac{Y-X}{X}=\cfrac{10^y-10^x}{10^x}=y-x-1$
    log data ä¸­ y è½´å˜åŒ–è¶Šå¤šï¼Œå¢é•¿ç‡è¶Šå¤§ï¼Œæ‰€ä»¥ log data ï¼š<br>
    <mark>åˆ»åº¦çº¿æ–œç‡â¬†ï¸ğŸŸ°å¢é•¿ç‡â¬†ï¸<br>åˆ»åº¦çº¿æ–œç‡â–ğŸŸ°å¢é•¿ç‡â–<br>åˆ»åº¦çº¿æ–œç‡â¬‡ï¸ğŸŸ°å¢é•¿ç‡â¬‡ï¸</mark>

![](./pics/log_3.png)
å‰ 50 å¤©ç—…ä¾‹ä» 0 å¢é•¿è¿œä½äº 10wï¼ˆçœ‹èµ·æ¥ä¾æ—§åœ¨0çš„é™„è¿‘ï¼‰ï¼Œå 50 å¤©ç—…ä¾‹ä»ä¸åˆ° 30w é£™åˆ°äº† 50wã€‚ä»é‡çš„å˜åŒ–æ¥è¯´ï¼Œè¶Šåé¢å¢åŠ çš„é‡è¶Šå¤§ã€‚
ä½†æ˜¯ä»æ„ŸæŸ“ç‡çš„å˜åŒ–æ¥è¯´ï¼Œå‰50å¤©çš„æ„ŸæŸ“ç‡è¿…é€Ÿé£™å‡ï¼Œå30å¤©çš„æ„ŸæŸ“ç‡å·²ç»´æŒç¨³å®šï¼Œè¯æ˜å·²ç»é€æ­¥ç¨³ä½è¶‹åŠ¿æˆ–è€…æ„ŸæŸ“äººæ•°å·²ç»æ¥è¿‘é¥±å’Œï¼Œå·²ç»æ¶¨ä¸äº†å¤šå°‘ã€‚

- [å‘Šè¯‰ä½ ä¸ºä»€ä¹ˆæ•°æ®è¦å–å¯¹æ•°](https://zhuanlan.zhihu.com/p/106232513)
- [Whatâ€™s A Logarithm?](https://readmedium.com/whats-a-logarithm-cca50d031241)
- [Logarithms â€” What, Why and How](https://towardsdatascience.com/logarithms-what-why-and-how-ff9d050d3fd7)

åæ–¹å·®ã€€è¡¡é‡ä¸€ä¸ªå˜é‡ä¸å¦ä¸€ä¸ªå˜é‡ï¼ˆåœ¨æ•°å€¼å’Œæ–¹å‘ä¸Šï¼‰ä¸€è‡´å˜åŒ–ç¨‹åº¦çš„æ–¹å¼ã€‚

## ç¬›å¡å°”ç§¯

AÃ—B={(x,y)|xâˆˆAâˆ§yâˆˆB}

A square matrix A is called a projection matrix if AA = A. If this is satisfied, then An = AÂ·Â·Â·A = A.

 The matrix AmÃ—m is called an orthogonal matrix if Aâˆ’1 = Aâ€². Therefore AAâ€² = Aâ€²A = I.

 The space spanned by a set of vectors {x1, Â· Â· Â· , xm}, is the totality of all the linear combinations of these vectors. A linear combination is like
c1x1 +Â·Â·Â·+cmxm,
where c1, Â· Â· Â· , cm are constants, and in particular, they can all be
zero.
â–¶ The range, or image of a matrix A, is the space spanned by the
vectors which are the columns of A.
â–¶ ThenullspaceofamatrixA,istheset{x:Ax=0}.

||Range|Null space|
|--|--|--|
|Identity Matrix|The whole space|The zero vector|
|Zero Matrix|The zero vector|The whole space|

## Vector

$$x=\begin{bmatrix}x_1\\x_2\\\vdots\\x_n\end{bmatrix}\in\R^{n\times1}\Longleftrightarrow x^T=\begin{bmatrix}x_1&x_2&\cdots&x_n\end{bmatrix}\in\R^{1\times n}$$

- ç®€å•çš„æ“ä½œ
    $cx =\begin{bmatrix}cx_1\\cx_2\\\vdots\\cx_n\end{bmatrix}$

    $x+y = \begin{bmatrix}x_1+y_1\\x_2+y_2\\\vdots\\x_n+y_n\end{bmatrix}$

    $<x, y> = <y, x>=x^Ty=y^Tx$

    $\Vert x\Vert =\sqrt{<x, x>} =\sqrt{x_1^2+x_2^2+\cdots+x_n^n}\\\Vert cx\Vert=c\Vert x\Vert$

    $\Vert x+y\Vert\le\Vert x\Vert+\Vert y\Vert$

## Matrix

$$A = []\in\R^{m\times n}$$

- ç®€å•çš„æ“ä½œ
    $A+B\Longleftrightarrow (A+B)_{i,j}=A_{i,j}+B_{i,j}$
    $A-B\Longleftrightarrow (A-B)_{i,j}=A_{i,j}-B_{i,j}$
    $cA\Longleftrightarrow (cA)_{i,j}=cA_{i,j}$

### ss

#### Square Matrix

$A\in\R^{n\times n}$

- invertible

### Matrices

$A\in\R^{n\times n}\xRightarrow{A^2=A}\text{projection}\xRightarrow{A=A^T}\text{orthogonal}$

#### symmetric matrix

#### invertible

## Derivatives

### vector

$x\in\R^n, A, B\in\R^{m\times n}, c\in\R^m$
$\cfrac{\partial}{\partial x}c^Tx=c$

$\cfrac{\partial}{\partial x}Ax=A^T$

$\cfrac{\partial }{\partial x}c^TAx=A^Tc$

$\cfrac{\partial }{\partial x}x^TAx= (A^T+A)x\xRightarrow{if A\in
 S}2Ax$

$\cfrac{\partial }{\partial x}x^TB^TAx=(B^TA+A^TB)x$

$\cfrac{\partial }{\partial x}x^Tx=(I^T+I)x=2x$

## å…³äºçº¦æŸæ¡ä»¶

!!! p "To solve: çº¦æŸæ¡ä»¶ä¸‹çš„å¯è¡ŒåŸŸç©ºé—´ä¸è§„åˆ™ï¼Œéš¾ä»¥æ±‚è§£ã€‚<u> å¸Œæœ›è½¬åŒ–ä¸ºè§„åˆ™çš„å¯è¡Œç©ºé—´</u>"

|$\min\limits_x f(x)\\\text{s.t.} h(x)=0,g(x)\le0\\\text{ä¸è§„åˆ™çš„çº¦æŸ}$ |$\implies$ |$\min\limits_x\max\limits_{\lambda,\mu} f(x)+\lambda h(x)+\mu g(x)\\\text{s.t.} \lambda,\mu\ge0\\\text{è§„åˆ™çš„çº¦æŸ}$|
|--|--|--|

**çº¦æŸæƒ…å†µ:**

$$\begin{align*}
\text{æ— çº¦æŸ}&\min f(x_1,\dots,x_n)\\
\text{ç­‰å¼çº¦æŸ}& \min f(x_1,\dots,x_n) \text{ s.t. }h(x_1,\dots,x_n)=0\\
\text{ä¸ç­‰å¼çº¦æŸ}&\min f(x_1,\dots,x_n) \text{ s.t. }g(x_1,\dots,x_n)\red{\le} 0
\end{align*}$$

### æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•, Lagrange Multiplier

!!! p "For æ±‚ $f(x_1,\dots,x_n)$ åœ¨ $k$ ä¸ªçº¦æŸæ¡ä»¶ $h_i(x) =\le 0, i=1,\dots, k$ä¸‹çš„æå€¼"
    å°†çº¦æŸæ¡ä»¶å‡½æ•°ä¸åŸå‡½æ•°è”ç«‹ï¼Œä»è€Œæ±‚å‡ºä½¿åŸå‡½æ•°å–å¾—æå€¼çš„å„ä¸ªå˜é‡çš„è§£ã€‚

$$\text{k ä¸ªç­‰å¼çº¦æŸ: } \min f(x_1,\dots,x_n) \text{ s.t. }h_j(x_1,\dots,x_n)=0, j=1, \dots,k\\
\Leftrightarrow \min_x\max_\alpha \mathcal{L}(x,\alpha):=\min_x\max_\alpha f(x)+\sum_{j=0}^k\alpha_jh_j(x)$$

To solve:

$$\cfrac{\partial \mathcal{L}}{\partial x}=\cfrac{\partial \mathcal{L}}{\partial \alpha_1}=\dots =\cfrac{\partial \mathcal{L}}{\partial \alpha_k}\xlongequal{SET}0$$

!!! danger "p ä¸ªç­‰å¼æ¡ä»¶ $h_j(x_1,\dots, x_n)=0, j=1,\dots,p$ <br> qä¸ªä¸ç­‰å¼æ¡ä»¶ $g_k(x_1, \dots, x_n)\red{\le}0, k=1,\dots,q$"

$$\min f(x_1,\dots,x_n) \text{ s.t. }\begin{cases}
h_j(x_1,\dots, x_n)=0, j=1,\dots,p\\g_k(x_1,\dots,x_n)\red{\le}0, k=1, \dots,q
\end{cases}\\
\Leftrightarrow  \mathcal{L}(x,\lambda,\mu):=f(x)+\sum_{j=0}^p\lambda_jh_j(x)+\sum_{k=1}^q\mu_kg_k(x)\\
\implies \min_{x}\max_{\lambda,\mu} \mathcal{L}(x,\lambda,\mu)$$

To solve:

$$\cfrac{\partial \mathcal{L}}{\partial x_i}=\cfrac{\partial \mathcal{L}}{\partial \lambda_j}=\cfrac{\partial \mathcal{L}}{\partial \mu_k}\xlongequal{SET}0$$

**è¯æ˜ï¼š$\min\limits_x\max\limits_{\lambda,\mu}$**
è®¨è®º $g(x)$ çš„å–å€¼ã€‚
- $g(x)\gt0$ï¼Œä¸åœ¨å¯è¡ŒåŸŸå†…ã€‚å…ˆæ±‚çš„ $\max\limits_\mu\rightarrow\infin\impliedby\mu\rightarrow+\infin$
- $g(x)\le0$ï¼Œåœ¨å¯è¡ŒåŸŸå†…ã€‚å…ˆæ±‚çš„ $\max\limits_\mu\rightarrow f(x)\impliedby\mu\rightarrow0\impliedby \mu\ge0$
$\implies\mathcal{L}(x,\lambda,\mu)=\begin{cases}f(x)&g(x)\le0\text{åœ¨å¯è¡ŒåŸŸå†…}\\+\infin&g(x)\ge0\text{ä¸åœ¨å¯è¡ŒåŸŸå†…}\end{cases}$
æ‰€ä»¥ä¸€æ—¦å¯è§£($\neq\infin$)ï¼Œå°±è‚¯å®šæ˜¯åœ¨å¯è¡ŒåŸŸå†…èŒƒå›´å†…æ±‚å¾—çš„è§£ã€‚

### å¯¹å¶é—®é¢˜

åŸå§‹å½¢å¼ï¼š$p^*:=\min\limits_x\max\limits_\lambda f(x)+\lambda h(x),\text{ s.t. }\lambda\ge0\rightarrow(x_p^*,\lambda_p^*)$
å¯¹å¶é—®é¢˜ï¼š$q^*:=\max\limits_\lambda\min\limits_x f(x)+\lambda h(x),\text{ s.t. }\lambda\ge0\rightarrow(x_q^*,\lambda_q^*)$

$p^* \& q^*$ å­˜åœ¨ $\implies p^*\ge q^*\begin{cases}p^*=q^*&\text{å¼ºå¯¹å¶}\\p^*>q^*&\text{å¼±å¯¹å¶}\end{cases}$

è¯æ˜ï¼š$p^*\ge q^*$,

Let $\mathcal{L}(x, \lambda)= f(x)+\lambda h(x)$
$\lambda_p^*=\max\limits_\lambda \mathcal{L}(x,\lambda)\implies \mathcal{L}(x,\lambda_p^*) \ge\forall x, \mathcal{L}(x, \lambda)$

$x_q^*=\min\limits_x \mathcal{L}(x,\lambda)\implies \mathcal{L}(x_q^*,\lambda) \le \forall \lambda, \mathcal{L}(x, \lambda)$

$$\mathcal{L}(x,\lambda_p^*)\ge\mathcal{L}(x, \lambda)\ge \mathcal{L}(x_q^*,\lambda)\\\implies p^*= \mathcal{L}(x_p^*,\lambda_p^*)\ge \mathcal{L}(x_q^*,\lambda_q^*)=q^*$$

#### KKT

!!! p "ä¸ºäº†è¾¾åˆ°å¼ºå¯¹å¶æ¡ä»¶ $p^*=q^*$ï¼ŒçœŸçš„æ‹¿åˆ°åŸé—®é¢˜çš„æœ€ä¼˜è§£ã€‚"

1. $f(x), g(x)$ ç›®æ ‡å‡½æ•°ï¼Œä¸ç­‰å¼çº¦æŸ æ˜¯å‡¸å‡½æ•°
2. $h(x)$ ç­‰åçº¦æŸ æ˜¯ ä»¿å°„å‡½æ•°
3. ä¸ç­‰å¼çº¦æŸå¯ä¸¥æ ¼ä¸ç­‰äº
4. éç‚¹æ¡ä»¶ $\cfrac{\partial \mathcal{L}(\cdot)}{\partial x}=\cfrac{\partial \mathcal{L}(\cdot)}{\partial \lambda}=\cfrac{\partial \mathcal{L}(\cdot)}{\partial \mu}\xlongequal{SET}0$
5. å¯è¡Œæ¡ä»¶ $\begin{cases} \lambda,\mu\ge0\\h(x)=0\\g(x)\le0\end{cases}$
6. äº’è¡¥æ¾å¼›æ¡ä»¶ $\mu g(x)=0$

## æ¦‚ç‡ & ç»Ÿè®¡

||æ¦‚ç‡|ç»Ÿè®¡
|--|--|--|
è¾“å…¥|è§„å¾‹|å¤§é‡æ ·æœ¬
è¾“å‡º|ç‰¹å®šæ ·æœ¬çš„æ¦‚ç‡|è§„å¾‹
å®è´¨<br>ä¼¼ç„¶å‡½æ•°|æ ¹æ®åˆ†å¸ƒè§„å¾‹æ¨ç®—æŸä¸€æ ·æœ¬<u>å‘ç”Ÿæ¦‚ç‡</u>|æ ¹æ®å¤§é‡æ ·æœ¬æ€»ç»“æ¨æ–­èƒŒåçš„è§„å¾‹<u>(å‚æ•°)</u>ã€‚<br> $\Updownarrow$å‡ºç°xæ ·æœ¬æ¦‚ç‡æœ€å¤§çš„å‚æ•°

==ä¼¯åŠªåˆ©å¤§æ•°å®šå¾‹==ï¼Œè®¾$f_A$æ˜¯næ¬¡ç‹¬ç«‹é‡å¤è¯•éªŒä¸­äº‹ä»¶Aå‘ç”Ÿçš„æ¬¡æ•°ã€‚Pæ˜¯Aåœ¨æ¯æ¬¡å®éªŒä¸­å‘ç”Ÿçš„æ¦‚ç‡ã€‚$\forall \epsilon\gt0,\lim\limits_{n\rightarrow\infin}P\{\vert\frac{f_A}{n}-p\vert<\epsilon\}=0$ã€‚å½“è¯•éªŒæ¬¡æ•°è¶‹å‘æ— ç©·æ—¶ï¼Œäº‹ä»¶ A å‘ç”Ÿçš„é¢‘ç‡<u>ä¾æ¦‚ç‡æ”¶æ•›äº</u>Aäº‹ä»¶åœ¨è¯•éªŒä¸­å‘ç”Ÿçš„æ¦‚ç‡ã€‚
==ä¸­å¿ƒæé™å®šç†==ï¼Œå¤§é‡ç›¸äº’ç‹¬ç«‹éšæœºå˜é‡çš„å‡å€¼ç»è¿‡é€‚å½“æ ‡å‡†åŒ–å<u>ä¾åˆ†å¸ƒæ”¶æ•›</u>äº<u>æ­£æ€åˆ†å¸ƒ</u>ã€‚

### æ¨¡å‹è¯„ä»·

|å®è´¨è®¡ç®—|æ¦‚ç‡è§’åº¦|ï½
|--|--|--|
æœ€å°äºŒä¹˜æ³• |æœ€å¤§ä¼¼ç„¶ä¼°è®¡ MAE| $(y-\hat{y})^2$
å²­å›å½’ |æœ€å¤§åéªŒä¼°è®¡ MAP|å¼•å…¥æ­£åˆ™é¡¹ $P(w), w^2$

æœ€å¤§ä¼¼ç„¶æ³• $\xrightarrow{\text{å¥ å®š}}\\\xrightarrow{\text{æ¦‚ç‡è§£é‡Š}}$ æœ€å°äºŒä¹˜æ³•
æœ€å¤§åéªŒä¼°è®¡ $\xrightarrow{\text{å¥ å®š}}\\\xrightarrow{\text{æ¦‚ç‡è§£é‡Š}}$ å²­å›å½’
(æœ€å°äºŒä¹˜æ³• & æœ€å¤§ä¼¼ç„¶æ³•),(å²­å›å½’ & æœ€å¤§åéªŒä¼°è®¡) **å½¢å¼å®è´¨ç›¸ç­‰ï¼Œå®è´¨æ€æƒ³ä¸€è‡´ï¼Œä½†å‡ºå‘è§’åº¦ä¸åŒ**

æœ€å¤§åéªŒä¼°è®¡æ˜¯å¢åŠ äº† $p(w)$å…ˆéªŒï¼Œä½œä¸ºæ­£åˆ™é¡¹å­˜åœ¨ã€‚

|ï½|æœ€å¤§ä¼¼ç„¶|æœ€å¤§åéªŒä¼°è®¡|
|--|--|--|
ç›®æ ‡å‡½æ•°|$P(x\vert w)$|$P(w\vert x)=\cfrac{P(x\vert w)P(w)}{P(x)}$
å‡è®¾|$\epsilonï½N(0,\sigma^2)$é«˜æ–¯å™ªå£°|$\epsilonï½N(0,\sigma_\epsilon^2)$é«˜æ–¯å™ªå£°<br>$wï½N(0,\sigma_w^2)$é«˜æ–¯å…ˆéªŒ

!!! p "è§£æ MAE & MAP"
    $$A:=\text{è½¦è¢«ç ¸äº†},\qquad\overline{A}:=\text{è½¦æ²¡è¢«ç ¸}\\B:=\text{è­¦æŠ¥å“äº†},\qquad\overline{B}:=\text{è­¦æŠ¥æ²¡å“}$$
    **ç»Ÿè®¡é—®é¢˜**ï¼šæœ‰å¤§é‡æ ·æœ¬ï¼Œå»æ¢è®¨è½¦è¢«ç ¸äº†å’Œè­¦æŠ¥å“äº†æœ‰ä»€ä¹ˆå…³ç³»
    **æ¦‚ç‡é—®é¢˜**ï¼šè­¦æŠ¥å“äº†ï¼Œæœ‰å¤šå°‘æ¦‚ç‡å¯ä»¥ç›¸ä¿¡è½¦æ˜¯è¢«ç ¸äº†
    |||
    |--|--|
    æœ€å¤§ä¼¼ç„¶ MAE| $P(B\vert A)$ åœ¨è½¦è¢«ç ¸äº†çš„æƒ…å†µä¸‹ è­¦æŠ¥å“äº†
    æœ€å¤§åéªŒä¼°è®¡ MAP| $P(A\vert B)=\cfrac{P(B\vert A)P(A)}{P(B)}=\cfrac{\text{ä¼¼ç„¶å‡½æ•°*å…ˆéªŒ}}{P(B)}$ åœ¨è­¦æŠ¥å“äº†çš„æƒ…å†µä¸‹ï¼Œè½¦è¢«ç ¸

    å¦‚æœä¸¤è€…å…·æœ‰å¼ºå…³è”æ€§ $P(A\vert B)\approx P(B\vert A)\rightarrow1$

!!! danger "$$\{(x_i, y_i)\vert i=1,\dots,n\}, x_i\in\R^d,y_i\in\R\\y_i=w^Tx_i+\epsilon_i=\hat{y}_i+\epsilon_i$$"

#### æœ€å°äºŒä¹˜æ³•

$$\min_{w^T}\mathcal{L}(w^T)=\frac{1}{2}\epsilon^2=\frac{1}{2}\sum_{i=1}^n(y_i-\hat{y}_i)^2\\\hat{y}=w^Tx$$

##### æœ€å¤§ä¼¼ç„¶ä¼°è®¡
å‡è®¾ <u>$\epsilonï½N(0,\sigma^2)$ï¼Œæœä»é«˜æ–¯åˆ†å¸ƒ</u>ã€‚$\begin{cases}yï½N(w^Tx,\sigma^2)\\P(y=y^*)=\cfrac{1}{\sqrt{2\pi}\sigma}\exp(-\cfrac{(y^*-w^Tx)^2}{2\sigma^2})\end{cases}$

$$\max_{w^T}\prod_{i=1}^nP(y_i)=\max_{w^T}\sum_{i=1}^n\log P(y_i)\\\begin{align*}
\max_{w^T}\mathcal{L}(w^T)&=\sum_{i=1}^n\log \Big[\cfrac{1}{\sqrt{2\pi}\sigma}\exp(-\cfrac{(y_i-w^Tx_i)^2}{2\sigma^2})\Big]\\
&=\sum_{i=1}^n \Big[-\log(\sqrt{2\pi}\sigma)-\cfrac{(y_i-w^Tx_i)^2}{2\sigma^2}\Big]\\
&\propto \min_{w^T}\sum_{i=1}^n(y_i-w^Tx_i)^2\\
&\propto \min_{w^T}\sum_{i=1}^n(y_i-\hat{y}_i)^2
\end{align*}$$

**æœ€å¤§ä¼¼ç„¶æ³•çš„ä¾æ®:**
- è¯¯å·®æ˜¯éšæœºã€æ— æ•°ã€ç‹¬ç«‹
- <u>ä¸­å¿ƒæé™å®šç†</u>(å¤§é‡ç›¸äº’ç‹¬ç«‹éšæœºå˜é‡çš„å‡å€¼ç»è¿‡é€‚å½“æ ‡å‡†åŒ–åä¾åˆ†å¸ƒæ”¶æ•›äºæ­£æ€åˆ†å¸ƒ)
$\implies$ è¯¯å·®æœä»æ­£æ€åˆ†å¸ƒ

è‹¥è¯¯å·®æ˜¯æ­£æ€åˆ†å¸ƒï¼Œåˆ™æœ€å°äºŒä¹˜æ³•å¾—æœ€ä¼˜è§£ä¹Ÿå¿…ç„¶æ˜¯æœ€ä¼˜è§£ã€‚

##### æœ€å¤§åéªŒä¼°è®¡
$$ \max_w P(w|x)=\cfrac{P(x|w)P(w)}{P(x)}$$
å‡è®¾:
- $\epsilon$ æœä»æ­£æ€åˆ†å¸ƒ $\begin{cases}\epsilonï½N(0,\sigma_\epsilon^2)\\yï½N(w^Tx,\sigma_\epsilon^2)\\P(y)=\cfrac{1}{\sqrt{2\pi}\sigma_\epsilon}\exp(-\cfrac{(y-w^Tx)^2}{2\sigma_\epsilon^2})\end{cases}$
- $w$ æœä»æ­£æ€åˆ†å¸ƒ $wï½N(0, \sigma_w^2), P(w)=\cfrac{1}{\sqrt{2\pi}\sigma_w}\exp(-\cfrac{w^2}{2\sigma_w^2})$

$$ \begin{align*}
\max_w P(w|x)&=\cfrac{P(x|w)P(w)}{P(x)}\\
&\propto P(x|w)P(w)\\
\Leftrightarrow\max_w\log P(w|x)&\propto \log P(x|w)+\log P(w)\\
&=-\log\sqrt{2\pi}(\sigma_1+\sigma_2)-\cfrac{(y-w^Tx)^2}{2\sigma_\epsilon^2}-\cfrac{w^2}{2\sigma_w^2}\\
&\propto-\cfrac{(y-w^Tx)^2}{2\sigma_\epsilon^2}-\cfrac{w^2}{2\sigma_w^2}\\
&\xrightarrow{\times-2\sigma_\epsilon^2}\min_w (y-w^Tx)^2+\cfrac{\sigma_\epsilon^2}{\sigma_w^2}w^2\\
&\xLeftrightarrow{=}\min_w(y-w^Tx)^2+\frac{\lambda}{2}w^2,\lambda=2\cfrac{\sigma_\epsilon^2}{\sigma_w^2}\text{ L1-penalty å²­å›å½’}
\end{align*}$$

## Simplicity (linear) and Optimality (minimal risk).

Risk function.

$R(Î´) = \int\limits_{f_X(z)>f_Y(z)}f_Y(z)dz + \int\limits_{f_X(z)â‰¤f_Y(z)}f_X(z)dz=\intÎ´(z)f_Y(z)dz+\int(1-Î´(z))f_X(z)dz$

Optimality:

$\forall Î´^*,R(Î´^*)-R(Î´)=\int(Î´^* âˆ’Î´)(f_Y(z)âˆ’f_X(z))dzâ‰¥0\impliedby Î´=I\{f_X(z) âˆ’ f_Y (z)\}.$

If X is greater than FY, our classifier says that OK, we are going to classify sample Z into class X.
Right.
Because the density, the likelihood that it comes from cost X is greater than class Y.
Right. And we are going to cut our decision our best through just now says that OK, in this case we are going to classify the sample into class X.
