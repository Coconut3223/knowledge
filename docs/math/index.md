# math

## logrithm

åœ¨æ•°æ®å¤„ç†ä¸­ï¼Œç»å¸¸ä¼šæŠŠåŸå§‹æ•°æ®å–å¯¹æ•°ä¹‹åå†å¤„ç†ï¼Œæ— è®ºæ˜¯åœ¨ç”»å›¾ï¼Œè¿˜æ˜¯åœ¨ da é‡Œã€‚
è®“æˆ‘å€‘åœ¨è™•ç†**æŒ‡æ•¸ç´šå¢é•·çš„äº‹ç‰©æ™‚å…·æœ‰æ›´å¤§çš„éˆæ´»æ€§(å°æ•¸å¹«åŠ©æˆ‘å€‘è™•ç†â€œéç·šæ€§â€æ•¸æ“šã€‚)**ã€‚èˆ‡æ™®éçœ‹æ³•ç›¸åï¼ŒæŒ‡æ•¸å¢é•·ä¸¦ä¸ç¸½æ˜¯åƒä¸€æ£µæ¨¹é•·åˆ°å¤©ç©ºä¸€æ¨£â€”â€”**å®ƒåƒ…åƒ…æ„å‘³è‘—æ•¸æ“šä»¥ç›¸ç•¶æ†å®šçš„é€Ÿåº¦è¤‡åˆï¼ˆæˆ–è¡°æ¸›ï¼‰**

**ä¸ºä»€ä¹ˆèƒ½è¿™æ ·åšï¼š**<br>
log æ˜¯å•è°ƒå¢å‡½æ•°ï¼Œä¸ä¼šæ”¹å˜æ•°æ®çš„ç›¸å¯¹å…³ç³»ã€‚

**ä¸ºä»€ä¹ˆè¦è¿™æ ·åšï¼š**

- ç¼©å°æ•°æ®çš„ç»å¯¹æ•°å€¼, æ–¹ä¾¿è®¡ç®—ã€‚å°¤å…¶æ˜¯å¯¹ä¸€äº›ç›´æ¥è®¡ç®—ä¼šè¶…è¿‡å¸¸ç”¨æ•°æ®ç±»å‹çš„å–å€¼èŒƒå›´ã€‚
    > æ¯”å¦‚ TF-IDF è®¡ç®— åœ¨å¤§è§„æ¨¡é¢„æ–™ä¸­ï¼Œå¸¸ç”¨è¯çš„é¢‘ç‡ä¼šéå¸¸å¤§ (I, æˆ‘)
    !!! p ""
        å…¶å®å°±è·Ÿ åƒä¸‡çº§åˆ«çš„æ•°å­— é™¤ä»¥åƒä¸‡ï¼Œä» $x*{10}^7\xrightarrow{\div{10}^7}x$ï¼Œå°±å¯ä»¥åœ¨é»˜è®¤æ˜¯åƒä¸‡çº§åˆ«åªå¯¹åƒä¸‡ä½ä¸Šè¿›è¡Œå¤„ç†ã€‚log å°±æ˜¯å…¶ä¸­ä¸€ç§ç¼©å°æ•°æ®çš„ç»å¯¹æ•°å€¼çš„æ–¹æ³•è€Œå·²ï¼Œåªæ˜¯å®ƒæ›´æ“…é•¿å¤„ç†æ•°æ®ä¹‹é—´ç›¸å·®éå¸¸å¤§ï¼Œç±»æŒ‡æ•°å¢åŠ æˆ–è¡°å‡çš„è¶‹åŠ¿çš„é—´è·ã€‚
- å–å¯¹æ•°åï¼Œå¯ä»¥å°†ä¹˜æ³•è®¡ç®— $\rightarrow$ åŠ æ³•è®¡ç®—ï¼Œæ›´å®¹æ˜“ç†è§£å¤§å°å…³ç³»ã€‚
    !!! warning è¿™ä¸ªç‰¹åˆ«å¸¸è§åœ¨å›¾ç‰‡ä¸­ï¼ï¼ï¼

    ``` python title = volume of planets
    planets= {
        'sun': 1.41*10**18,
        'jupiter': 1.43*10**15
        'earth': 1.83*10**12,
        'moon': 2.20*10**10
    }
    ```

    <div class="grid" markdown>
    <figure markdown="span">![](./pics/log_1.png)<p>ä¸ç»è¿‡å¤„ç†ä¹‹å‰ï¼Œåªèƒ½çŸ¥é“ Sun æ˜¯ä¸€éª‘ç»å°˜çš„å¤§ï¼Œä½†æ˜¯è¿™ä¸ªä¸€éª‘ç»å°˜åˆ°åº•æ˜¯å¤šä¸€éª‘ç»å°˜ä¹Ÿä¸çŸ¥é“ï¼Œé™¤æ­¤ä¹‹å¤–å…¶å®ƒ items æ˜¯ä¸çŸ¥é“ç›¸å¯¹å¤§å°çš„ï¼Œæ‰€ä»¥ä¸å¥½ã€‚</p></figure>
    <figure markdown="span">![](./pics/log_2.png)<p>å¾ˆæ˜ç¡®çŸ¥é“ç›¸å¯¹å¤§å°å…³ç³»ï¼Œè€Œä¸”: Sun åœ¨ 18ï¼ŒJupiter åœ¨ 15ï¼Œä¸¤è€…ç›¸å·®äº†3ï¼Œå°±æ˜¯$10^3$ é‡çº§ã€‚</p></figure>
    <div>
    > æ¸¬é‡åœ°éœ‡å¼·åº¦ã€‚é€™è¢«ç¨±ç‚ºé‡Œæ°éœ‡ç´šï¼Œçµ¦å‡ºäº†ä»¥ 10 ç‚ºåº•çš„å°æ•¸çš„åœ°éœ‡å¼·åº¦ã€‚ 6.0ç´šåœ°éœ‡æ¯”5.0ç´šåœ°éœ‡å¼·10å€
- åœ¨æ•°å€¼å°çš„åœºæ™¯æ¯”æ•°å€¼å¤§çš„æ—¶å€™å¯¹å·®å¼‚æ›´æ•æ„Ÿã€‚æ˜¯ä¸€ä¸ªè¿™ç¬¦åˆæŸäº›åº”ç”¨åœºæ™¯ã€‚
    > å¯¹äºä»·æ ¼ï¼Œç™¾å…ƒä¸‹çš„å·®å‡ ç™¾ & åƒå…ƒçš„å·®å‡ ç™¾ ä¸æ˜¯ä¸€ä¸ªæ•æ„Ÿç¨‹åº¦ã€‚
    > å¯¹äºä¸­æ–‡åˆ†è¯ï¼Œèƒ½åˆ†æˆ $A_1(200) \& A_2(800)$ & $B_1(500) \& B_2(500)$ï¼Œå•çº¯æ¯”è¾ƒé¢‘ç‡å’Œéƒ½æ˜¯1000ï¼Œæ— æ³•è¾¨æ¸…ä¼˜åŠ£ã€‚ä½†æ˜¯æ¯”è¾ƒå¯¹æ•°å’Œ $\begin{cases}A=\log_{10}(200)+\log_{10}(800)\approx2.30103+2.90308\approx5.2\\B:2\log_{10}(500)\approx2*2.69897\approx5.4\end{cases}\implies B>A$ åå‘éƒ½æ˜¯å¸¸è§çš„æƒ…å†µï¼Œé€‰æ‹© B çš„æ–¹æ¡ˆã€‚
- æ‰€å¾—åˆ°çš„æ•°æ®æ˜“æ¶ˆé™¤å¼‚æ–¹å·®é—®é¢˜ã€‚ã€ä¸æ‡‚ã€‘
- åœ¨ç»æµå­¦ä¸­ï¼Œå¸¸å–è‡ªç„¶å¯¹æ•°å†åšå›å½’ï¼Œè¿™æ—¶å›å½’æ–¹ç¨‹ä¸º lnY=a lnX+b ï¼Œä¸¤è¾¹åŒæ—¶å¯¹Xæ±‚å¯¼ï¼Œ1/Y*(DY/DX)=a*1/X, b=(DY/DX)*(X/Y)=(DY*X)/(DX*Y)=(DY/Y)/(DX/X) è¿™æ­£å¥½æ˜¯å¼¹æ€§çš„å®šä¹‰ã€‚ã€ä¸æ‡‚ã€‘

!!! danger "å®è·µä¸­ï¼Œå–å¯¹æ•°çš„ä¸€èˆ¬æ˜¯æ°´å¹³é‡ï¼Œè€Œä¸æ˜¯æ¯”ä¾‹æ•°æ®ï¼Œä¾‹å¦‚å˜åŒ–ç‡ç­‰ã€‚"

!!! question "æ•°æ®é›†æœ‰è´Ÿæ•°ï¼Œå¯ä¸å¯ä»¥é€šè¿‡åŠ ä¸€ä¸ªåº•æ•°ï¼Œä½¿å¾—æ•´ä½“æ•°æ®ä¸ºæ­£å†log å¤„ç†"

!!! danger â€œå…³äºè¶‹åŠ¿çš„é”™è§‰ï¼šå¢åŠ é‡ & å¢é•¿é€Ÿç‡â€
    å¢åŠ é‡ $=Y-X$, å¢åŠ é€Ÿç‡ $=\cfrac{Y-X}{X}$
    å¢åŠ é‡å¤§ä¸ä»£è¡¨å¢åŠ é€Ÿç‡å¤§ï¼Œè€Œæ˜¯è¦è¿›è¡Œè®¡ç®—ã€‚é€šè¿‡ raw data æˆ‘ä»¬èƒ½æ„Ÿè§‰â€œé‡â€çš„å˜åŒ–ï¼Œé€šè¿‡ log data æˆ‘ä»¬èƒ½æ„Ÿåˆ°â€œé€Ÿç‡çš„å˜åŒ–â€ã€‚<br>
    $\begin{cases}x:=\log_{10}X\\y:=\log_{10}Y\end{cases}\implies \cfrac{Y-X}{X}=\cfrac{10^y-10^x}{10^x}=y-x-1$
    log data ä¸­ y è½´å˜åŒ–è¶Šå¤šï¼Œå¢é•¿ç‡è¶Šå¤§ï¼Œæ‰€ä»¥ log data ï¼š<br>
    <mark>åˆ»åº¦çº¿æ–œç‡â¬†ï¸ğŸŸ°å¢é•¿ç‡â¬†ï¸<br>åˆ»åº¦çº¿æ–œç‡â–ğŸŸ°å¢é•¿ç‡â–<br>åˆ»åº¦çº¿æ–œç‡â¬‡ï¸ğŸŸ°å¢é•¿ç‡â¬‡ï¸</mark>

![](./pics/log_3.png)
å‰ 50 å¤©ç—…ä¾‹ä» 0 å¢é•¿è¿œä½äº 10wï¼ˆçœ‹èµ·æ¥ä¾æ—§åœ¨0çš„é™„è¿‘ï¼‰ï¼Œå 50 å¤©ç—…ä¾‹ä»ä¸åˆ° 30w é£™åˆ°äº† 50wã€‚ä»é‡çš„å˜åŒ–æ¥è¯´ï¼Œè¶Šåé¢å¢åŠ çš„é‡è¶Šå¤§ã€‚
ä½†æ˜¯ä»æ„ŸæŸ“ç‡çš„å˜åŒ–æ¥è¯´ï¼Œå‰50å¤©çš„æ„ŸæŸ“ç‡è¿…é€Ÿé£™å‡ï¼Œå30å¤©çš„æ„ŸæŸ“ç‡å·²ç»´æŒç¨³å®šï¼Œè¯æ˜å·²ç»é€æ­¥ç¨³ä½è¶‹åŠ¿æˆ–è€…æ„ŸæŸ“äººæ•°å·²ç»æ¥è¿‘é¥±å’Œï¼Œå·²ç»æ¶¨ä¸äº†å¤šå°‘ã€‚

- [å‘Šè¯‰ä½ ä¸ºä»€ä¹ˆæ•°æ®è¦å–å¯¹æ•°](https://zhuanlan.zhihu.com/p/106232513)
- [Whatâ€™s A Logarithm?](https://readmedium.com/whats-a-logarithm-cca50d031241)
- [Logarithms â€” What, Why and How](https://towardsdatascience.com/logarithms-what-why-and-how-ff9d050d3fd7)

åæ–¹å·®ã€€è¡¡é‡ä¸€ä¸ªå˜é‡ä¸å¦ä¸€ä¸ªå˜é‡ï¼ˆåœ¨æ•°å€¼å’Œæ–¹å‘ä¸Šï¼‰ä¸€è‡´å˜åŒ–ç¨‹åº¦çš„æ–¹å¼ã€‚

## ç¬›å¡å°”ç§¯

AÃ—B={(x,y)|xâˆˆAâˆ§yâˆˆB}

A square matrix A is called a projection matrix if AA = A. If this is satisfied, then An = AÂ·Â·Â·A = A.

 The matrix AmÃ—m is called an orthogonal matrix if Aâˆ’1 = Aâ€². Therefore AAâ€² = Aâ€²A = I.

 The space spanned by a set of vectors {x1, Â· Â· Â· , xm}, is the totality of all the linear combinations of these vectors. A linear combination is like
c1x1 +Â·Â·Â·+cmxm,
where c1, Â· Â· Â· , cm are constants, and in particular, they can all be
zero.
â–¶ The range, or image of a matrix A, is the space spanned by the
vectors which are the columns of A.
â–¶ ThenullspaceofamatrixA,istheset{x:Ax=0}.

||Range|Null space|
|--|--|--|
|Identity Matrix|The whole space|The zero vector|
|Zero Matrix|The zero vector|The whole space|

## Vector

$$x=\begin{bmatrix}x_1\\x_2\\\vdots\\x_n\end{bmatrix}\in\R^{n\times1}\Longleftrightarrow x^T=\begin{bmatrix}x_1&x_2&\cdots&x_n\end{bmatrix}\in\R^{1\times n}$$

- ç®€å•çš„æ“ä½œ
    $cx =\begin{bmatrix}cx_1\\cx_2\\\vdots\\cx_n\end{bmatrix}$

    $x+y = \begin{bmatrix}x_1+y_1\\x_2+y_2\\\vdots\\x_n+y_n\end{bmatrix}$

    $<x, y> = <y, x>=x^Ty=y^Tx$

    $\Vert x\Vert =\sqrt{<x, x>} =\sqrt{x_1^2+x_2^2+\cdots+x_n^n}\\\Vert cx\Vert=c\Vert x\Vert$

    $\Vert x+y\Vert\le\Vert x\Vert+\Vert y\Vert$

## Matrix

$$A = []\in\R^{m\times n}$$

- ç®€å•çš„æ“ä½œ
    $A+B\Longleftrightarrow (A+B)_{i,j}=A_{i,j}+B_{i,j}$
    $A-B\Longleftrightarrow (A-B)_{i,j}=A_{i,j}-B_{i,j}$
    $cA\Longleftrightarrow (cA)_{i,j}=cA_{i,j}$

### ss

#### Square Matrix

$A\in\R^{n\times n}$

- invertible

### Matrices

$A\in\R^{n\times n}\xRightarrow{A^2=A}\text{projection}\xRightarrow{A=A^T}\text{orthogonal}$

#### symmetric matrix

#### invertible

## Derivatives

### vector

$x\in\R^n, A, B\in\R^{m\times n}, c\in\R^m$
$\cfrac{\partial}{\partial x}c^Tx=c$

$\cfrac{\partial}{\partial x}Ax=A^T$

$\cfrac{\partial }{\partial x}c^TAx=A^Tc$

$\cfrac{\partial }{\partial x}x^TAx= (A^T+A)x\xRightarrow{if A\in
 S}2Ax$

$\cfrac{\partial }{\partial x}x^TB^TAx=(B^TA+A^TB)x$

$\cfrac{\partial }{\partial x}x^Tx=(I^T+I)x=2x$

## å…³äºçº¦æŸæ¡ä»¶

!!! p "To solve: çº¦æŸæ¡ä»¶ä¸‹çš„å¯è¡ŒåŸŸç©ºé—´ä¸è§„åˆ™ï¼Œéš¾ä»¥æ±‚è§£ã€‚<u> å¸Œæœ›è½¬åŒ–ä¸ºè§„åˆ™çš„å¯è¡Œç©ºé—´</u>"

|$\min\limits_x f(x)\\\text{s.t.} h(x)=0,g(x)\le0\\\text{ä¸è§„åˆ™çš„çº¦æŸ}$ |$\implies$ |$\min\limits_x\max\limits_{\lambda,\mu} f(x)+\lambda h(x)+\mu g(x)\\\text{s.t.} \lambda,\mu\ge0\\\text{è§„åˆ™çš„çº¦æŸ}$|
|--|--|--|

**çº¦æŸæƒ…å†µ:**

$$\begin{align*}
\text{æ— çº¦æŸ}&\min f(x_1,\dots,x_n)\\
\text{ç­‰å¼çº¦æŸ}& \min f(x_1,\dots,x_n) \text{ s.t. }h(x_1,\dots,x_n)=0\\
\text{ä¸ç­‰å¼çº¦æŸ}&\min f(x_1,\dots,x_n) \text{ s.t. }g(x_1,\dots,x_n)\red{\le} 0
\end{align*}$$

### æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•, Lagrange Multiplier

!!! p "For æ±‚ $f(x_1,\dots,x_n)$ åœ¨ $k$ ä¸ªçº¦æŸæ¡ä»¶ $h_i(x) =\le 0, i=1,\dots, k$ä¸‹çš„æå€¼"
    å°†çº¦æŸæ¡ä»¶å‡½æ•°ä¸åŸå‡½æ•°è”ç«‹ï¼Œä»è€Œæ±‚å‡ºä½¿åŸå‡½æ•°å–å¾—æå€¼çš„å„ä¸ªå˜é‡çš„è§£ã€‚

$$\text{k ä¸ªç­‰å¼çº¦æŸ: } \min f(x_1,\dots,x_n) \text{ s.t. }h_j(x_1,\dots,x_n)=0, j=1, \dots,k\\
\Leftrightarrow \min_x\max_\alpha \mathcal{L}(x,\alpha):=\min_x\max_\alpha f(x)+\sum_{j=0}^k\alpha_jh_j(x)$$

To solve:

$$\cfrac{\partial \mathcal{L}}{\partial x}=\cfrac{\partial \mathcal{L}}{\partial \alpha_1}=\dots =\cfrac{\partial \mathcal{L}}{\partial \alpha_k}\xlongequal{SET}0$$

!!! danger "p ä¸ªç­‰å¼æ¡ä»¶ $h_j(x_1,\dots, x_n)=0, j=1,\dots,p$ <br> qä¸ªä¸ç­‰å¼æ¡ä»¶ $g_k(x_1, \dots, x_n)\red{\le}0, k=1,\dots,q$"

$$\min f(x_1,\dots,x_n) \text{ s.t. }\begin{cases}
h_j(x_1,\dots, x_n)=0, j=1,\dots,p\\g_k(x_1,\dots,x_n)\red{\le}0, k=1, \dots,q
\end{cases}\\
\Leftrightarrow  \mathcal{L}(x,\lambda,\mu):=f(x)+\sum_{j=0}^p\lambda_jh_j(x)+\sum_{k=1}^q\mu_kg_k(x)\\
\implies \min_{x}\max_{\lambda,\mu} \mathcal{L}(x,\lambda,\mu)$$

To solve:

$$\cfrac{\partial \mathcal{L}}{\partial x_i}=\cfrac{\partial \mathcal{L}}{\partial \lambda_j}=\cfrac{\partial \mathcal{L}}{\partial \mu_k}\xlongequal{SET}0$$

**è¯æ˜ï¼š$\min\limits_x\max\limits_{\lambda,\mu}$**
è®¨è®º $g(x)$ çš„å–å€¼ã€‚
- $g(x)\gt0$ï¼Œä¸åœ¨å¯è¡ŒåŸŸå†…ã€‚å…ˆæ±‚çš„ $\max\limits_\mu\rightarrow\infin\impliedby\mu\rightarrow+\infin$
- $g(x)\le0$ï¼Œåœ¨å¯è¡ŒåŸŸå†…ã€‚å…ˆæ±‚çš„ $\max\limits_\mu\rightarrow f(x)\impliedby\mu\rightarrow0\impliedby \mu\ge0$
$\implies\mathcal{L}(x,\lambda,\mu)=\begin{cases}f(x)&g(x)\le0\text{åœ¨å¯è¡ŒåŸŸå†…}\\+\infin&g(x)\ge0\text{ä¸åœ¨å¯è¡ŒåŸŸå†…}\end{cases}$
æ‰€ä»¥ä¸€æ—¦å¯è§£($\neq\infin$)ï¼Œå°±è‚¯å®šæ˜¯åœ¨å¯è¡ŒåŸŸå†…èŒƒå›´å†…æ±‚å¾—çš„è§£ã€‚

### å¯¹å¶é—®é¢˜

åŸå§‹å½¢å¼ï¼š$p^*:=\min\limits_x\max\limits_\lambda f(x)+\lambda h(x),\text{ s.t. }\lambda\ge0\rightarrow(x_p^*,\lambda_p^*)$
å¯¹å¶é—®é¢˜ï¼š$q^*:=\max\limits_\lambda\min\limits_x f(x)+\lambda h(x),\text{ s.t. }\lambda\ge0\rightarrow(x_q^*,\lambda_q^*)$

$p^* \& q^*$ å­˜åœ¨ $\implies p^*\ge q^*\begin{cases}p^*=q^*&\text{å¼ºå¯¹å¶}\\p^*>q^*&\text{å¼±å¯¹å¶}\end{cases}$

è¯æ˜ï¼š$p^*\ge q^*$,

Let $\mathcal{L}(x, \lambda)= f(x)+\lambda h(x)$
$\lambda_p^*=\max\limits_\lambda \mathcal{L}(x,\lambda)\implies \mathcal{L}(x,\lambda_p^*) \ge\forall x, \mathcal{L}(x, \lambda)$

$x_q^*=\min\limits_x \mathcal{L}(x,\lambda)\implies \mathcal{L}(x_q^*,\lambda) \le \forall \lambda, \mathcal{L}(x, \lambda)$

$$\mathcal{L}(x,\lambda_p^*)\ge\mathcal{L}(x, \lambda)\ge \mathcal{L}(x_q^*,\lambda)\\\implies p^*= \mathcal{L}(x_p^*,\lambda_p^*)\ge \mathcal{L}(x_q^*,\lambda_q^*)=q^*$$

#### KKT

!!! p "ä¸ºäº†è¾¾åˆ°å¼ºå¯¹å¶æ¡ä»¶ $p^*=q^*$ï¼ŒçœŸçš„æ‹¿åˆ°åŸé—®é¢˜çš„æœ€ä¼˜è§£ã€‚"

1. $f(x), g(x)$ ç›®æ ‡å‡½æ•°ï¼Œä¸ç­‰å¼çº¦æŸ æ˜¯å‡¸å‡½æ•°
2. $h(x)$ ç­‰åçº¦æŸ æ˜¯ ä»¿å°„å‡½æ•°
3. ä¸ç­‰å¼çº¦æŸå¯ä¸¥æ ¼ä¸ç­‰äº
4. éç‚¹æ¡ä»¶ $\cfrac{\partial \mathcal{L}(\cdot)}{\partial x}=\cfrac{\partial \mathcal{L}(\cdot)}{\partial \lambda}=\cfrac{\partial \mathcal{L}(\cdot)}{\partial \mu}\xlongequal{SET}0$
5. å¯è¡Œæ¡ä»¶ $\begin{cases} \lambda,\mu\ge0\\h(x)=0\\g(x)\le0\end{cases}$
6. äº’è¡¥æ¾å¼›æ¡ä»¶ $\mu g(x)=0$

## æ¦‚ç‡ & ç»Ÿè®¡

||æ¦‚ç‡|ç»Ÿè®¡
|--|--|--|
è¾“å…¥|è§„å¾‹|å¤§é‡æ ·æœ¬
è¾“å‡º|ç‰¹å®šæ ·æœ¬çš„æ¦‚ç‡|è§„å¾‹
å®è´¨<br>ä¼¼ç„¶å‡½æ•°|æ ¹æ®åˆ†å¸ƒè§„å¾‹æ¨ç®—æŸä¸€æ ·æœ¬<u>å‘ç”Ÿæ¦‚ç‡</u>|æ ¹æ®å¤§é‡æ ·æœ¬æ€»ç»“æ¨æ–­èƒŒåçš„è§„å¾‹<u>(å‚æ•°)</u>ã€‚<br> $\Updownarrow$å‡ºç°xæ ·æœ¬æ¦‚ç‡æœ€å¤§çš„å‚æ•°

==ä¼¯åŠªåˆ©å¤§æ•°å®šå¾‹==ï¼Œè®¾$f_A$æ˜¯næ¬¡ç‹¬ç«‹é‡å¤è¯•éªŒä¸­äº‹ä»¶Aå‘ç”Ÿçš„æ¬¡æ•°ã€‚Pæ˜¯Aåœ¨æ¯æ¬¡å®éªŒä¸­å‘ç”Ÿçš„æ¦‚ç‡ã€‚$\forall \epsilon\gt0,\lim\limits_{n\rightarrow\infin}P\{\vert\frac{f_A}{n}-p\vert<\epsilon\}=0$ã€‚å½“è¯•éªŒæ¬¡æ•°è¶‹å‘æ— ç©·æ—¶ï¼Œäº‹ä»¶ A å‘ç”Ÿçš„é¢‘ç‡<u>ä¾æ¦‚ç‡æ”¶æ•›äº</u>Aäº‹ä»¶åœ¨è¯•éªŒä¸­å‘ç”Ÿçš„æ¦‚ç‡ã€‚
==ä¸­å¿ƒæé™å®šç†==ï¼Œå¤§é‡ç›¸äº’ç‹¬ç«‹éšæœºå˜é‡çš„å‡å€¼ç»è¿‡é€‚å½“æ ‡å‡†åŒ–å<u>ä¾åˆ†å¸ƒæ”¶æ•›</u>äº<u>æ­£æ€åˆ†å¸ƒ</u>ã€‚

### æ¨¡å‹è¯„ä»·

|å®è´¨è®¡ç®—|æ¦‚ç‡è§’åº¦|ï½
|--|--|--|
æœ€å°äºŒä¹˜æ³• |æœ€å¤§ä¼¼ç„¶ä¼°è®¡ MAE| $(y-\hat{y})^2$
å²­å›å½’ |æœ€å¤§åéªŒä¼°è®¡ MAP|å¼•å…¥æ­£åˆ™é¡¹ $P(w), w^2$

æœ€å¤§ä¼¼ç„¶æ³• $\xrightarrow{\text{å¥ å®š}}\\\xrightarrow{\text{æ¦‚ç‡è§£é‡Š}}$ æœ€å°äºŒä¹˜æ³•
æœ€å¤§åéªŒä¼°è®¡ $\xrightarrow{\text{å¥ å®š}}\\\xrightarrow{\text{æ¦‚ç‡è§£é‡Š}}$ å²­å›å½’
(æœ€å°äºŒä¹˜æ³• & æœ€å¤§ä¼¼ç„¶æ³•),(å²­å›å½’ & æœ€å¤§åéªŒä¼°è®¡) **å½¢å¼å®è´¨ç›¸ç­‰ï¼Œå®è´¨æ€æƒ³ä¸€è‡´ï¼Œä½†å‡ºå‘è§’åº¦ä¸åŒ**

æœ€å¤§åéªŒä¼°è®¡æ˜¯å¢åŠ äº† $p(w)$å…ˆéªŒï¼Œä½œä¸ºæ­£åˆ™é¡¹å­˜åœ¨ã€‚

|ï½|æœ€å¤§ä¼¼ç„¶|æœ€å¤§åéªŒä¼°è®¡|
|--|--|--|
ç›®æ ‡å‡½æ•°|$P(x\vert w)$|$P(w\vert x)=\cfrac{P(x\vert w)P(w)}{P(x)}$
å‡è®¾|$\epsilonï½N(0,\sigma^2)$é«˜æ–¯å™ªå£°|$\epsilonï½N(0,\sigma_\epsilon^2)$é«˜æ–¯å™ªå£°<br>$wï½N(0,\sigma_w^2)$é«˜æ–¯å…ˆéªŒ

!!! p "è§£æ MAE & MAP"
    $$A:=\text{è½¦è¢«ç ¸äº†},\qquad\overline{A}:=\text{è½¦æ²¡è¢«ç ¸}\\B:=\text{è­¦æŠ¥å“äº†},\qquad\overline{B}:=\text{è­¦æŠ¥æ²¡å“}$$
    **ç»Ÿè®¡é—®é¢˜**ï¼šæœ‰å¤§é‡æ ·æœ¬ï¼Œå»æ¢è®¨è½¦è¢«ç ¸äº†å’Œè­¦æŠ¥å“äº†æœ‰ä»€ä¹ˆå…³ç³»
    **æ¦‚ç‡é—®é¢˜**ï¼šè­¦æŠ¥å“äº†ï¼Œæœ‰å¤šå°‘æ¦‚ç‡å¯ä»¥ç›¸ä¿¡è½¦æ˜¯è¢«ç ¸äº†
    |||
    |--|--|
    æœ€å¤§ä¼¼ç„¶ MAE| $P(B\vert A)$ åœ¨è½¦è¢«ç ¸äº†çš„æƒ…å†µä¸‹ è­¦æŠ¥å“äº†
    æœ€å¤§åéªŒä¼°è®¡ MAP| $P(A\vert B)=\cfrac{P(B\vert A)P(A)}{P(B)}=\cfrac{\text{ä¼¼ç„¶å‡½æ•°*å…ˆéªŒ}}{P(B)}$ åœ¨è­¦æŠ¥å“äº†çš„æƒ…å†µä¸‹ï¼Œè½¦è¢«ç ¸

    å¦‚æœä¸¤è€…å…·æœ‰å¼ºå…³è”æ€§ $P(A\vert B)\approx P(B\vert A)\rightarrow1$

!!! danger "$$\{(x_i, y_i)\vert i=1,\dots,n\}, x_i\in\R^d,y_i\in\R\\y_i=w^Tx_i+\epsilon_i=\hat{y}_i+\epsilon_i$$"

#### æœ€å°äºŒä¹˜æ³•

$$\min_{w^T}\mathcal{L}(w^T)=\frac{1}{2}\epsilon^2=\frac{1}{2}\sum_{i=1}^n(y_i-\hat{y}_i)^2\\\hat{y}=w^Tx$$

##### æœ€å¤§ä¼¼ç„¶ä¼°è®¡
å‡è®¾ <u>$\epsilonï½N(0,\sigma^2)$ï¼Œæœä»é«˜æ–¯åˆ†å¸ƒ</u>ã€‚$\begin{cases}yï½N(w^Tx,\sigma^2)\\P(y=y^*)=\cfrac{1}{\sqrt{2\pi}\sigma}\exp(-\cfrac{(y^*-w^Tx)^2}{2\sigma^2})\end{cases}$

$$\max_{w^T}\prod_{i=1}^nP(y_i)=\max_{w^T}\sum_{i=1}^n\log P(y_i)\\\begin{align*}
\max_{w^T}\mathcal{L}(w^T)&=\sum_{i=1}^n\log \Big[\cfrac{1}{\sqrt{2\pi}\sigma}\exp(-\cfrac{(y_i-w^Tx_i)^2}{2\sigma^2})\Big]\\
&=\sum_{i=1}^n \Big[-\log(\sqrt{2\pi}\sigma)-\cfrac{(y_i-w^Tx_i)^2}{2\sigma^2}\Big]\\
&\propto \min_{w^T}\sum_{i=1}^n(y_i-w^Tx_i)^2\\
&\propto \min_{w^T}\sum_{i=1}^n(y_i-\hat{y}_i)^2
\end{align*}$$

**æœ€å¤§ä¼¼ç„¶æ³•çš„ä¾æ®:**
- è¯¯å·®æ˜¯éšæœºã€æ— æ•°ã€ç‹¬ç«‹
- <u>ä¸­å¿ƒæé™å®šç†</u>(å¤§é‡ç›¸äº’ç‹¬ç«‹éšæœºå˜é‡çš„å‡å€¼ç»è¿‡é€‚å½“æ ‡å‡†åŒ–åä¾åˆ†å¸ƒæ”¶æ•›äºæ­£æ€åˆ†å¸ƒ)
$\implies$ è¯¯å·®æœä»æ­£æ€åˆ†å¸ƒ

è‹¥è¯¯å·®æ˜¯æ­£æ€åˆ†å¸ƒï¼Œåˆ™æœ€å°äºŒä¹˜æ³•å¾—æœ€ä¼˜è§£ä¹Ÿå¿…ç„¶æ˜¯æœ€ä¼˜è§£ã€‚

##### æœ€å¤§åéªŒä¼°è®¡
$$ \max_w P(w|x)=\cfrac{P(x|w)P(w)}{P(x)}$$
å‡è®¾:
- $\epsilon$ æœä»æ­£æ€åˆ†å¸ƒ $\begin{cases}\epsilonï½N(0,\sigma_\epsilon^2)\\yï½N(w^Tx,\sigma_\epsilon^2)\\P(y)=\cfrac{1}{\sqrt{2\pi}\sigma_\epsilon}\exp(-\cfrac{(y-w^Tx)^2}{2\sigma_\epsilon^2})\end{cases}$
- $w$ æœä»æ­£æ€åˆ†å¸ƒ $wï½N(0, \sigma_w^2), P(w)=\cfrac{1}{\sqrt{2\pi}\sigma_w}\exp(-\cfrac{w^2}{2\sigma_w^2})$

$$ \begin{align*}
\max_w P(w|x)&=\cfrac{P(x|w)P(w)}{P(x)}\\
&\propto P(x|w)P(w)\\
\Leftrightarrow\max_w\log P(w|x)&\propto \log P(x|w)+\log P(w)\\
&=-\log\sqrt{2\pi}(\sigma_1+\sigma_2)-\cfrac{(y-w^Tx)^2}{2\sigma_\epsilon^2}-\cfrac{w^2}{2\sigma_w^2}\\
&\propto-\cfrac{(y-w^Tx)^2}{2\sigma_\epsilon^2}-\cfrac{w^2}{2\sigma_w^2}\\
&\xrightarrow{\times-2\sigma_\epsilon^2}\min_w (y-w^Tx)^2+\cfrac{\sigma_\epsilon^2}{\sigma_w^2}w^2\\
&\xLeftrightarrow{=}\min_w(y-w^Tx)^2+\frac{\lambda}{2}w^2,\lambda=2\cfrac{\sigma_\epsilon^2}{\sigma_w^2}\text{ L1-penalty å²­å›å½’}
\end{align*}$$

## Simplicity (linear) and Optimality (minimal risk).

Risk function.

$R(Î´) = \int\limits_{f_X(z)>f_Y(z)}f_Y(z)dz + \int\limits_{f_X(z)â‰¤f_Y(z)}f_X(z)dz=\intÎ´(z)f_Y(z)dz+\int(1-Î´(z))f_X(z)dz$

Optimality:

$\forall Î´^*,R(Î´^*)-R(Î´)=\int(Î´^* âˆ’Î´)(f_Y(z)âˆ’f_X(z))dzâ‰¥0\impliedby Î´=I\{f_X(z) âˆ’ f_Y (z)\}.$

If X is greater than FY, our classifier says that OK, we are going to classify sample Z into class X.
Right.
Because the density, the likelihood that it comes from cost X is greater than class Y.
Right. And we are going to cut our decision our best through just now says that OK, in this case we are going to classify the sample into class X.

## Entropy ç†µ

==Entropy ç†µ==ã€‚æ˜¯ä¸€ç¨®å°ç‰©ç†ç³»çµ±ä¹‹ç„¡ç§©åºæˆ–äº‚åº¦çš„é‡åº¦ã€‚

!!! p "ä¿¡æ¯é‡ & ç†µ å°±æ˜¯äº’è¡¥çš„å…³ç³»ï¼Œä¿¡æ¯é‡å°±æ˜¯è´Ÿç†µã€‚"
    ç†µ å¯ä»¥ç”¨æ¥è¡¡é‡æ¥æ”¶åˆ°çš„ä¿¡æ¯ï¼Œè·å¾—ä¿¡æ¯åï¼Œ<br>
    ç³»ç»Ÿè¶Šæ— åºè¶Šéšæœºï¼Œç†µå¢ï¼›ç³»ç»Ÿè¶Šæœ‰åºè¶Šç¡®å®šï¼Œç†µå‡ã€‚

| ?                        | High Entropy     | Low Entropy                     |
|--------------------------|------------------|---------------------------------|
| Distribution of variable | uniform like     | may have many peaks and valleys |
| histogram                | Flat             | may have many lows and highs    |
| Values sampled from it   | less predictable | more predictable                |
| information(about label) | Less             | More                            |

> We flip two different coins independently for 16 times, which have the following results:<br>
> Sequence 1 : 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 [0:1=12:4]<br>
> Sequence 2 : 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 [0:1=8:8]<br>
> Compute the information content (entropy) of the outcome of tossing these two coins, respectively.<br>
> I(conin_toss_1)= $-0.75\log_2(0.75)-0.25\log_2(0.25)=0.811$ bits <br>
> I(conin_toss_2)= $-0.5\log_2(0.5)-0.5\log_2(0.5)=1$ bits <br>

### èµ·æº

ä¿¡æ¯è®ºä¸­ç†µçš„æ¦‚å¿µé¦–æ¬¡è¢«é¦™å†œæå‡ºï¼Œç›®çš„æ˜¯å¯»æ‰¾ä¸€ç§é«˜æ•ˆ/æ— æŸåœ°ç¼–ç ä¿¡æ¯çš„æ–¹æ³•ï¼šä»¥ç¼–ç åæ•°æ®çš„å¹³å‡é•¿åº¦æ¥è¡¡é‡é«˜æ•ˆæ€§ï¼Œå¹³å‡é•¿åº¦è¶Šå°è¶Šé«˜æ•ˆï¼›åŒæ—¶è¿˜éœ€æ»¡è¶³â€œæ— æŸâ€çš„æ¡ä»¶ï¼Œå³ç¼–ç åä¸èƒ½æœ‰åŸå§‹ä¿¡æ¯çš„ä¸¢å¤±ã€‚è¿™æ ·ï¼Œé¦™å†œæå‡ºäº†ç†µçš„å®šä¹‰ï¼š**æ— æŸç¼–ç äº‹ä»¶ä¿¡æ¯çš„æœ€å°å¹³å‡ç¼–ç é•¿åº¦**

å¯¹äº N ç§ä¿¡æ¯ï¼Œä½¿ç”¨ 0-1 çš„äºŒå€¼ bitï¼Œéœ€è¦ $\log_2N$ bits è¡¨ç¤ºã€‚åœ¨è¿™æ ·çš„æƒ…å†µä¸‹ï¼Œæ¯ä¸€ä¸ªäº‹ä»¶è¡¨ç¤ºéƒ½ä¸èƒ½ç¼ºå°‘ä¸€ä½ï¼Œå¦åˆ™å°±ä¼šå¼•èµ·æ­§ä¹‰ï¼ŒåŒæ—¶ä¹Ÿä¸éœ€è¦å¤šä½™çš„ bits æ¥è¿›è¡Œç¼–ç ã€‚æ‰€ä»¥æ¯ä¸ªè¡¨ç¤ºçš„ä½æ•°éƒ½æ˜¯æ’å®š $\text{AVL}=\log_2N(P_1+\dots+P_N)=\log_2N$(æ’å®šçš„)

ä½†å…¶å®å¯ä»¥é€‰æ‹©åœ¨æ— æŸçš„æƒ…å†µä¸‹ï¼ŒæŠŠé«˜å¯èƒ½äº‹ä»¶ä½¿ç”¨çŸ­ç¼–ç (å‡å°‘ä½æ•°)ï¼Œå¯¹ä½å¯èƒ½äº‹ä»¶ä½¿ç”¨é•¿ç¼–ç ï¼ˆå¢åŠ ä½æ•°ï¼‰ã€‚è¿™å°±æ˜¯ ==éœå¤«æ›¼ç¢¼ Huffman Code==ã€‚

<div class="grid" style="grid-template-columns: repeat(3, 1fr) !important;"markdown>
<figure markdown="span" style="grid-column-start: 1; grid-column-end: 3;">![](./pics/entropy_1.webp)</figure>
<p style="grid-column-start: 3; grid-column-end: 4;">alpha è¦å‘ä¸€ä¸²ä¿¡æ¯ç»™ betaï¼Œ å‘é€çš„ä¿¡æ¯æ˜¯ä¸€ä¸ªéšæœºé‡ï¼Œæ¦‚ç‡å¹¶ä¸å‡ç­‰ã€‚é€šè¿‡ç¼–ç çš„å¹³å‡é•¿åº¦éªŒè¯å“ªä¸ªç¼–ç æ¯”è¾ƒæœ‰æ•ˆç‡ã€‚<br><b>åœ¨éœå°”æ›¼ç¼–ç ä¸­ï¼Œæ¯ä¸€ä¸ªäº‹ä»¶çš„è¡¨ç¤ºä½æ•°å¹¶ä¸æ˜¯æ’å®šï¼Œåœ¨ä¸€äº›é«˜å¯èƒ½äº‹ä»¶ AE é‡Œä»…é‡‡ç”¨ä¸¤ä½ç”šè‡³ä¸€ä½è¿›è¡Œè¡¨ç¤ºï¼Œåœ¨ BD é‡Œé‡‡ç”¨æ›´å¤šçš„ä½æ•°è¿›è¡Œè¡¨ç¤º</b></p>
</div>

!!! p "ç¼©çŸ­ä½æ•°çš„åŒæ—¶ç›¸åº”çš„å¯¹æŸäº›äº‹ä»¶çš„è¡¨ç¤ºè¿›è¡Œå¢åŠ ä½æ•°ï¼Œå¦åˆ™ä¼šå¼•èµ·æ­§ä¹‰"
    å¦‚æœåœ¨éœå°”æ›¼ç¼–ç çš„æ—¶å€™ï¼Œåªç¼©å‡ AE çš„ç¼–ç ï¼ŒBD ç»´æŒåŸå½¢

    |A|B|C|D|E
    |--|--|--|--|--|
    |10(0)|001|010|011|0(00)|

    å°±ä¼šäº§ç”Ÿæ­§ä¹‰ï¼š010 = 010 C ï½œ 0_10 E_A 
    æ‰€ä»¥å…¶å®å°±æ˜¯é€šè¿‡å‡å°‘ä¸€äº›è¡¨ç¤ºçš„ä½æ•°æ¥ç¼©å‡å¹³å‡ç¼–ç é•¿åº¦ï¼Œåˆé€šè¿‡å¢åŠ ä¸€äº›è¡¨ç¤ºçš„ä½æ•°æ¥æ¶ˆé™¤æ­§ä¹‰ã€‚<br> å¹³å‡ç¼–ç é•¿åº¦åˆè·Ÿæ¦‚ç‡æŒ‚é’©ï¼Œæ‰€ä»¥é€‰æ‹©é«˜æ¦‚ç‡ç¼©å‡ï¼Œä½æ¦‚ç‡å¢åŠ æ¶ˆé™¤æ­§ä¹‰ã€‚

<div class="grid" style="grid-template-columns: repeat(3, 1fr) !important;"markdown>
<figure markdown="span" style="grid-column-start: 1; grid-column-end: 3;">![](./pics/entropy_2.webp)</figure>
<p style="grid-column-start: 3; grid-column-end: 4;">å•çº¯ç›´æ¥äºŒè¿›åˆ¶ç¼–ç éœ€è¦å¹³å‡ 24/40 çš„ç¼–ç é•¿åº¦ï¼Œéœå°”æ›¼ç¼–ç åªéœ€è¦å¹³å‡ 15/40 çš„ç¼–ç é•¿åº¦</p>
</div>

<div class="grid" style="grid-template-columns: repeat(3, 1fr) !important;"markdown>
<figure markdown="span" style="grid-column-start: 1; grid-column-end: 3;">![](./pics/entropy_3.webp)<p>éœå¤«æ›¼ç·¨ç¢¼é•·åº¦ & Entropy ä¹‹é–“çš„é—œä¿‚</p></figure>
<p style="grid-column-start: 3; grid-column-end: 4;">é‡‡ç”¨ 2 ä¸ºåŸºï¼Œ$E=-P(x)\log_2^P(x)$<br>$E(A)=-\cfrac{1}{4}\log_2\cfrac{1}{4}=\cfrac{1}{4}\log_24=2/8$</p>
</div>

**é‚£ä¹ˆæ€ä¹ˆç¡®è®¤æ— æŸç¼–ç çš„æœ€å°å¹³å‡å¤§å°ï¼Œä¹Ÿå°±æ˜¯ç†µï¼Ÿ**

**ç”¨æ¯ç§æŠ¥æ–‡ç±»å‹çš„æœ€å°ç¼–ç å¤§å°æ¥è®¡ç®—å¹³å‡ç¼–ç å¤§å°ã€‚**

å†è¯´ä¸€æ¬¡ï¼šä¸€èˆ¬ç”¨ bits æ¥å¯¹ N ç§ä¿¡æ¯è¡¨ç¤ºï¼Œéœ€è¦ $\log_2N$ bitsã€‚<br>
æ¢è¨€ä¹‹ï¼Œå¦‚æœä¸€ç§ä¿¡æ¯åœ¨ N æ¬¡å‡ºç°ä¸€æ¬¡ï¼Œæ‰€éœ€çš„**æœ€å°å¤§å°**æ˜¯ $\log_2N$ã€‚

!!! p "ä¸ºä»€ä¹ˆè¿™é‡Œæ˜¯æœ€å°çš„å¤§å°æ˜¯ $\log_2N$ï¼Œä¸æ˜¯è¯´æœ‰äº›è¡¨ç¤ºè¦å»¶é•¿ä½æ•°å—ï¼Ÿ"
    è¿˜æ˜¯ä»¥ABCDEçš„äº‹æƒ…ä¸ºä¾‹å­ï¼š
    **æœ€å°å•ä½æ˜¯1æ¬¡ã€‚** BD å‡ºç°çš„æ¦‚ç‡æ˜¯ $\cfrac{1}{16}$,ä¹Ÿå°±æ˜¯ 16 æ¬¡é‡Œå‡ºç°ä¸€æ¬¡ï¼Œè¿™é‡Œçš„ N æ˜¯ 16ï¼Œè€Œä¸æ˜¯5ç§ä¿¡æ¯çš„5ã€‚æ‰€éœ€æœ€å°å¤§å°æ˜¯ $\log_2(16)=4\neq\log_25$

$$\log_2N=-\log_2(\cfrac{1}{N})=-\log_2(P)\\\text{AVL=Entropy}=-\sum_iP(i)\log_2P(i)$$

### ç†µçš„ç±»æ¯” & æ„ä¹‰

å…³äºç†µï¼Œæœ‰å¾ˆå¤šç±»æ¯”ï¼šæ— åºã€ä¸ç¡®å®šæ€§ã€æƒŠå–œã€ä¸å¯é¢„æµ‹æ€§ã€ä¿¡æ¯é‡ç­‰ç­‰ã€‚

å¦‚æœç†µå¾ˆé«˜ï¼Œå°±æ„å‘³ç€æˆ‘ä»¬æ²¡æœ‰å¾ˆå¤šé«˜æ¦‚ç‡äº‹ä»¶è¿›è¡Œç¼©å‡ç¼–ç ï¼Œæ¯ä¸ªä¿¡æ¯çš„ç¼–ç éƒ½å¾ˆå¤§ï¼ˆä¿¡æ¯é‡å¤§ï¼‰ï¼Œå½“äº‹ä»¶çš„å¯èƒ½æ€§éƒ½ç›¸å·®ä¸å¤§ï¼Œé‚£ä¹ˆéšæœºæ€§å°±ä¼šå¾ˆå¤§ï¼›å¦‚æœç†µå¾ˆä½ï¼Œæ„å‘³ç€æˆ‘ä»¬æœ‰å¾ˆå¤šé«˜æ¦‚ç‡äº‹ä»¶æ¥ç¼©å‡ç¼–ç ï¼Œæˆ‘ä»¬æ›´å®¹æ˜“æ”¶åˆ°çŸ­çš„ç¼–ç å°±æ˜¯ï¼ˆä¿¡æ¯é‡å°‘ï¼‰ï¼ŒæŸä¸€äº‹ä»¶å¯èƒ½æ€§è¶Šå¤§ï¼Œäº‹æƒ…å°±å……æ»¡ç¡®å®šæ€§ã€‚

[Entropy (ç†µ)æ˜¯ç”šéº¼ï¼Ÿåœ¨è³‡è¨Šé ˜åŸŸçš„ç”¨é€”æ˜¯ï¼Ÿ](https://medium.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7-%E5%80%92%E5%BA%95%E6%9C%89%E5%A4%9A%E6%99%BA%E6%85%A7/entropy-%E7%86%B5-%E6%98%AF%E7%94%9A%E9%BA%BC-%E5%9C%A8%E8%B3%87%E8%A8%8A%E9%A0%98%E5%9F%9F%E7%9A%84%E7%94%A8%E9%80%94%E6%98%AF-1551e55110fa)
